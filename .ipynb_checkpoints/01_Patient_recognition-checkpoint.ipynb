{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c0c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the corresponding libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c080d6c-85bf-4a1a-b9bb-42ebd9cccd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Apache Parquet DataSet\n",
    "'''\n",
    "Each of the files for this project contains 2 tabs. For instance:\n",
    "The file completo800_(edit).xlsx contains the tabs:\n",
    "\n",
    "* totale\n",
    "* Foglio 1\n",
    "\n",
    "For performance reasons the original .xlsx files were converted to Apache_Parquet files\n",
    "After this transformation the only remainig tab is\n",
    "\n",
    "* totale\n",
    "\n",
    "which contains all the data concerning to the research\n",
    "''' \n",
    "#DataFrame used for deployment\n",
    "# '/Users/luisescobar/Documents/Thesis/DataSets/Apache_parquet/completo_800_output_file.parquet'\n",
    "\n",
    "path_to_read = '/Users/luisescobar/Documents/Thesis/DataSets/Apache_parquet'\n",
    "path_to_save = '/Users/luisescobar/Documents/Thesis/DataSets/Dictionary'\n",
    "file = 'completo1007_(edit).parquet'\n",
    "name_read = f'{path_to_read}/{file}'\n",
    "df = pd.read_parquet(name_read, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4936df-1a2f-42cd-b04c-3a85618a44ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Date__Heure</th>\n",
       "      <th>P_Access</th>\n",
       "      <th>P_Filter</th>\n",
       "      <th>P_Effluent</th>\n",
       "      <th>P_Return</th>\n",
       "      <th>FIFTH_PRESSURE</th>\n",
       "      <th>RUN_TIME</th>\n",
       "      <th>Post_Replacement</th>\n",
       "      <th>Pre_Replacement</th>\n",
       "      <th>...</th>\n",
       "      <th>Citric_Acid_Concentration__mmol_</th>\n",
       "      <th>Citrate_Dose__mmol_L_</th>\n",
       "      <th>Calcium_Compensation____</th>\n",
       "      <th>Calcium_syringe_Concentration__m</th>\n",
       "      <th>Treatment_Duration__h_</th>\n",
       "      <th>effluent2</th>\n",
       "      <th>delta_eff</th>\n",
       "      <th>max_line</th>\n",
       "      <th>reverse</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-28 22:58:00</td>\n",
       "      <td>54</td>\n",
       "      <td>-25</td>\n",
       "      <td>-26</td>\n",
       "      <td>-38</td>\n",
       "      <td>-37</td>\n",
       "      <td>73854</td>\n",
       "      <td>31168</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>35.179443</td>\n",
       "      <td>109341</td>\n",
       "      <td>-23</td>\n",
       "      <td>3710</td>\n",
       "      <td>2119</td>\n",
       "      <td>-146001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-28 22:59:00</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>-13</td>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "      <td>73878</td>\n",
       "      <td>31170</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>35.179443</td>\n",
       "      <td>109423</td>\n",
       "      <td>-82</td>\n",
       "      <td>3710</td>\n",
       "      <td>2118</td>\n",
       "      <td>-145978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-28 23:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>94</td>\n",
       "      <td>-1</td>\n",
       "      <td>60</td>\n",
       "      <td>-2</td>\n",
       "      <td>73938</td>\n",
       "      <td>31192</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>35.179443</td>\n",
       "      <td>109497</td>\n",
       "      <td>-74</td>\n",
       "      <td>3710</td>\n",
       "      <td>2117</td>\n",
       "      <td>-145896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-28 23:01:00</td>\n",
       "      <td>27</td>\n",
       "      <td>121</td>\n",
       "      <td>28</td>\n",
       "      <td>95</td>\n",
       "      <td>-3</td>\n",
       "      <td>73998</td>\n",
       "      <td>31218</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>35.179443</td>\n",
       "      <td>109570</td>\n",
       "      <td>-73</td>\n",
       "      <td>3710</td>\n",
       "      <td>2116</td>\n",
       "      <td>-145822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-28 23:02:00</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>19</td>\n",
       "      <td>72</td>\n",
       "      <td>-3</td>\n",
       "      <td>74058</td>\n",
       "      <td>31238</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>35.179443</td>\n",
       "      <td>109647</td>\n",
       "      <td>-77</td>\n",
       "      <td>3710</td>\n",
       "      <td>2115</td>\n",
       "      <td>-145749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient         Date__Heure  P_Access  P_Filter  P_Effluent  P_Return  \\\n",
       "0      NaN 2011-07-28 22:58:00        54       -25         -26       -38   \n",
       "1      NaN 2011-07-28 22:59:00         7        57         -13        33   \n",
       "2      NaN 2011-07-28 23:00:00         7        94          -1        60   \n",
       "3      NaN 2011-07-28 23:01:00        27       121          28        95   \n",
       "4      NaN 2011-07-28 23:02:00         6       112          19        72   \n",
       "\n",
       "   FIFTH_PRESSURE  RUN_TIME  Post_Replacement  Pre_Replacement  ...  \\\n",
       "0             -37     73854             31168                0  ...   \n",
       "1              -1     73878             31170                0  ...   \n",
       "2              -2     73938             31192                0  ...   \n",
       "3              -3     73998             31218                0  ...   \n",
       "4              -3     74058             31238                0  ...   \n",
       "\n",
       "   Citric_Acid_Concentration__mmol_  Citrate_Dose__mmol_L_  \\\n",
       "0                                 _                      _   \n",
       "1                                 _                      _   \n",
       "2                                 _                      _   \n",
       "3                                 _                      _   \n",
       "4                                 _                      _   \n",
       "\n",
       "   Calcium_Compensation____  Calcium_syringe_Concentration__m  \\\n",
       "0                         _                                 _   \n",
       "1                         _                                 _   \n",
       "2                         _                                 _   \n",
       "3                         _                                 _   \n",
       "4                         _                                 _   \n",
       "\n",
       "   Treatment_Duration__h_  effluent2  delta_eff  max_line  reverse     sum  \n",
       "0               35.179443     109341        -23      3710     2119 -146001  \n",
       "1               35.179443     109423        -82      3710     2118 -145978  \n",
       "2               35.179443     109497        -74      3710     2117 -145896  \n",
       "3               35.179443     109570        -73      3710     2116 -145822  \n",
       "4               35.179443     109647        -77      3710     2115 -145749  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abee5dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289492 entries, 0 to 289491\n",
      "Data columns (total 94 columns):\n",
      " #   Column                            Non-Null Count   Dtype         \n",
      "---  ------                            --------------   -----         \n",
      " 0   Patient                           0 non-null       float64       \n",
      " 1   Date__Heure                       289492 non-null  datetime64[ns]\n",
      " 2   P_Access                          289492 non-null  int64         \n",
      " 3   P_Filter                          289492 non-null  int64         \n",
      " 4   P_Effluent                        289492 non-null  int64         \n",
      " 5   P_Return                          289492 non-null  int64         \n",
      " 6   FIFTH_PRESSURE                    289492 non-null  int64         \n",
      " 7   RUN_TIME                          289492 non-null  int64         \n",
      " 8   Post_Replacement                  289492 non-null  int64         \n",
      " 9   Pre_Replacement                   289492 non-null  int64         \n",
      " 10  Dialysate                         289492 non-null  int64         \n",
      " 11  Effluent                          289492 non-null  int64         \n",
      " 12  Pre_Blood_Pump                    289492 non-null  int64         \n",
      " 13  SYRINGE_INF                       289492 non-null  int64         \n",
      " 14  EXCESS_PT_FLUID                   289492 non-null  int64         \n",
      " 15  PUMP_PBP                          289492 non-null  float64       \n",
      " 16  PUMP_Rep                          289492 non-null  float64       \n",
      " 17  PUMP_Dial                         289492 non-null  float64       \n",
      " 18  PUMP_Eff                          289492 non-null  float64       \n",
      " 19  Q_Blood_Pump                      289492 non-null  int64         \n",
      " 20  Q_Replacement                     289492 non-null  int64         \n",
      " 21  Q_Dialysate                       289492 non-null  int64         \n",
      " 22  Q_PBP                             289492 non-null  int64         \n",
      " 23  Q_Patient_Fluid_Removal           289492 non-null  int64         \n",
      " 24  Patient_Fluid_Removal             289492 non-null  int64         \n",
      " 25  DeltaP                            289492 non-null  int64         \n",
      " 26  TMP                               289492 non-null  float64       \n",
      " 27  TMPa                              289492 non-null  int64         \n",
      " 28  Q_Effluent                        289492 non-null  int64         \n",
      " 29  Ratio                             289492 non-null  int64         \n",
      " 30  Q_syringe                         289492 non-null  float64       \n",
      " 31  Q_syringe_Calcium                 289492 non-null  float64       \n",
      " 32  Citrate_Dose                      289492 non-null  float64       \n",
      " 33  Calcium_Comp                      289492 non-null  int64         \n",
      " 34  F35                               0 non-null       float64       \n",
      " 35  F36                               0 non-null       float64       \n",
      " 36  F37                               0 non-null       float64       \n",
      " 37  F38                               0 non-null       float64       \n",
      " 38  F39                               0 non-null       float64       \n",
      " 39  F40                               0 non-null       float64       \n",
      " 40  F41                               0 non-null       float64       \n",
      " 41  trt                               289492 non-null  int64         \n",
      " 42  line                              289492 non-null  int64         \n",
      " 43  F1                                289492 non-null  int64         \n",
      " 44  F2                                289492 non-null  int64         \n",
      " 45  Patient_weight__Kg_               280976 non-null  float64       \n",
      " 46  Therapy                           289492 non-null  object        \n",
      " 47  Anticoagulation_selected_         289492 non-null  object        \n",
      " 48  Qb__mL_min_                       289492 non-null  int64         \n",
      " 49  Qpbp__ml_h_                       289492 non-null  int64         \n",
      " 50  Qd__ml_h_                         289492 non-null  int64         \n",
      " 51  Qr__ml_h_                         289492 non-null  int64         \n",
      " 52  __PRE_POST                        289492 non-null  float64       \n",
      " 53  Qpfr__ml_h_                       289492 non-null  int64         \n",
      " 54  Set                               289492 non-null  object        \n",
      " 55  Run_Time__s_                      289492 non-null  int64         \n",
      " 56  Blood_Return                      289492 non-null  object        \n",
      " 57  Nb_Blood_Recirculation            289492 non-null  int64         \n",
      " 58  Blood_Recirculation_duration__mi  289492 non-null  float64       \n",
      " 59  Warning_during_treatment          289492 non-null  int64         \n",
      " 60  Nb_Bag_Changes                    289492 non-null  int64         \n",
      " 61  Total_mean_duration_per_Bag_Chan  289492 non-null  float64       \n",
      " 62  Acc_Ret_warning                   289492 non-null  int64         \n",
      " 63  End_Cause                         289492 non-null  object        \n",
      " 64  Dialysate_done__g_                289492 non-null  int64         \n",
      " 65  Dialysate_Expected__g_            289492 non-null  float64       \n",
      " 66  Delta_Dialysate__g_               289492 non-null  int64         \n",
      " 67  Pre_Replace_done__g_              289492 non-null  int64         \n",
      " 68  Post_Replace_done__g_             289492 non-null  int64         \n",
      " 69  Replace_done__g_                  289492 non-null  int64         \n",
      " 70  Replace_Expected__g_              289492 non-null  float64       \n",
      " 71  Delta_Replace__g_                 289492 non-null  int64         \n",
      " 72  PBP_done__g_                      289492 non-null  int64         \n",
      " 73  PBP_Expected__g_                  289492 non-null  float64       \n",
      " 74  Delta_PBP__g_                     289492 non-null  int64         \n",
      " 75  Effluent_done__g_                 289492 non-null  int64         \n",
      " 76  PFR_done__g_                      289492 non-null  int64         \n",
      " 77  PFR_Expected__g_                  289492 non-null  float64       \n",
      " 78  Delta_PFR__g_                     289492 non-null  int64         \n",
      " 79  Start_hour__hh_mm_                289492 non-null  object        \n",
      " 80  Start_line                        289492 non-null  int64         \n",
      " 81  Stop_line                         289492 non-null  int64         \n",
      " 82  Citrate_Solution                  289492 non-null  object        \n",
      " 83  Citrate_Concentration__mmol_L_    289492 non-null  object        \n",
      " 84  Citric_Acid_Concentration__mmol_  289492 non-null  object        \n",
      " 85  Citrate_Dose__mmol_L_             289492 non-null  object        \n",
      " 86  Calcium_Compensation____          289492 non-null  object        \n",
      " 87  Calcium_syringe_Concentration__m  289492 non-null  object        \n",
      " 88  Treatment_Duration__h_            289492 non-null  float64       \n",
      " 89  effluent2                         289492 non-null  int64         \n",
      " 90  delta_eff                         289492 non-null  int64         \n",
      " 91  max_line                          289492 non-null  int64         \n",
      " 92  reverse                           289492 non-null  int64         \n",
      " 93  sum                               289492 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(25), int64(56), object(12)\n",
      "memory usage: 207.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#Info of the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88da049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_trt(df_spec_col):\n",
    "    '''The function returns a dictionary with keys associated to\n",
    "    the different treatment 'trt' values\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_spec_col : pandas.core.frame.DataFrame\n",
    "        DataFrame with specific columns related to the research focus \n",
    "\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df_dict : dict\n",
    "        Dictionary with DataFrames divided according to the treatment 'trt' value.\n",
    "        The output of dict.keys will be something as follows\n",
    "            dict_keys(['df_601', 'df_602', 'df_603', 'df_604', 'df_605', ...\n",
    "        df_601 is by itself a DataFrame with all the information corresponding to the\n",
    "        treatment 'trt' 601\n",
    "    '''\n",
    "    \n",
    "    #List with the different treatments values\n",
    "    trt = df_spec_col[\"trt\"].unique()\n",
    "    df_dict = {}\n",
    "\n",
    "    for value in trt:\n",
    "        # Create a dataframe for each unique value in trt and store it in the dictionary\n",
    "        df_dict[f\"df_{value}\"] = df_spec_col[df_spec_col['trt'] == value]\n",
    "        \n",
    "    return df_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd9da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_weight_vis(df_dict):\n",
    "    '''The function returns a sub DataFrame with the columns \n",
    "    trt and Patient_weight__Kg_\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dict : dict\n",
    "        Dictionary organized according to the different treatments 'trt'\n",
    "        values\n",
    "\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame with 'weight' set as index and 'trt' as reference value \n",
    "        the 'weight' (index) is sorted ascending\n",
    "        \n",
    "                    \n",
    "        weight(index)----trt\n",
    "        7.0--------------706\n",
    "        7.0--------------702\n",
    "        45.0-------------616\n",
    "        45.0-------------613\n",
    "        46.0-------------618\n",
    "\n",
    "    '''\n",
    "    merge_dict = {\n",
    "        'trt':[],\n",
    "        'weight':[]\n",
    "    }\n",
    "    for value in df_dict.keys():\n",
    "        df = df_dict[value]\n",
    "        trt = df[\"trt\"].unique()\n",
    "        weight = df[\"Patient_weight__Kg_\"].unique()\n",
    "        merge_dict['trt'].extend(trt)\n",
    "        merge_dict['weight'].extend(weight)\n",
    "        \n",
    "    df = pd.DataFrame(merge_dict)\n",
    "    df = df.sort_values(by=['weight', 'trt']).reset_index(drop=True)\n",
    "    df = df.set_index(\"weight\", inplace=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8623ed0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  <p>\n",
    "    <b>To Do</b>\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    I would like to have a function in which I choose, arbitrary, the maximum difference, between trt values, and according to this merge the DataFrames\n",
    "  </p>\n",
    "    \n",
    "  <p>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62c246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_to_merge(df, tolerance):\n",
    "    '''The function returns a DataFrame with boolean information, in the column merge, to \n",
    "    join DataFrames that correspond to the same patient\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame containing just the 'trt' and 'weight' value for all the cases of interest. Output of the \n",
    "        trt_weight_vis function\n",
    "        \n",
    "    tolerance : int\n",
    "        Tolerance of difference between the treatment values corresponding to a patient with the \n",
    "        same weight\n",
    "        i.e., a tolerance of 1 indicates that given the follwing DataFrame\n",
    "        \n",
    "            weight   trt    diff    tolerance   merge\n",
    "        [0] 7.0      702    4.0     False       False\n",
    "        [1] 7.0      706    93.0    False       False\n",
    "        [2] 45.0     613    3.0     False       False\n",
    "        [3] 45.0     616    2.0     False       False\n",
    "        [4] 46.0     618    1.0     True        True\n",
    "        [5] 46.0     619    7.0     False       False\n",
    "        \n",
    "        The row [4] will be True since, is the only one in which, the difference between trt[i] and \n",
    "        trt[i+1] is 1\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame with the following columns\n",
    "        ['weight'   'trt'    'diff'    'tolerance'   'merge']\n",
    "        \n",
    "        weight(index): weight value of the different patients\n",
    "        trt: treatment value\n",
    "        diff: difference between consecutive treatment values after sorting the DataFrame\n",
    "        tolerance:  if diff <= tolerance\n",
    "                        return True\n",
    "                    else\n",
    "                        return False\n",
    "        merge:  if (df['tolerance'] == True) & (shifted_index == df.index)\n",
    "                    return True\n",
    "                else\n",
    "                    return True\n",
    "        \n",
    "        shifted_index is the value of the index in the position [i+1] \n",
    "        \n",
    "        where: \n",
    "            i is the current index position \n",
    "                    \n",
    "    '''\n",
    "    # Shifting the 'trt' column by one position\n",
    "    df['shifted_trt'] = df['trt'].shift(-1)\n",
    "\n",
    "    # Calculating the difference between the 'trt' column and the shifted 'trt' column\n",
    "    df['diff'] = abs(df['trt'] - df['shifted_trt'])\n",
    "\n",
    "    # Dropping the 'shifted_trt' column as it's no longer needed\n",
    "    df.drop(columns=['shifted_trt'], inplace=True)\n",
    "    \n",
    "    #Search values in which the diff is <= tolerance\n",
    "    df['tolerance'] = df['diff'] <= tolerance\n",
    "    \n",
    "    #Create a new column merge to do the final comparison between trt values and weight values\n",
    "    shifted_index = df.index.to_series().shift(-1)\n",
    "    df['merge'] = ((df['tolerance'] == True) & (shifted_index == df.index))\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0152ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_recognition(df, columns, tolerance):\n",
    "    '''The function returns a DataFrame with columns containing information\n",
    "    useful to match patients with 'trt' number. This is a global function, cointaining all the \n",
    "    previous defined functions.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame with all the patients information\n",
    "    columns : list\n",
    "        Columns of interest i.e.,\n",
    "        columns=[\"Date__Heure\",\"P_Access\",\"P_Filter\",\"P_Effluent\",\"P_Return\", ...\n",
    "    tolerance : int\n",
    "        Tolerance of difference between the treatment values corresponding to a patient with the \n",
    "        same weight\n",
    "        i.e., a tolerance of 1 indicates that given the follwing DataFrame\n",
    "        \n",
    "            weight   trt    diff    tolerance   merge\n",
    "        [0] 7.0      702    4.0     False       False\n",
    "        [1] 7.0      706    93.0    False       False\n",
    "        [2] 45.0     613    3.0     False       False\n",
    "        [3] 45.0     616    2.0     False       False\n",
    "        [4] 46.0     618    1.0     True        True\n",
    "        [5] 46.0     619    7.0     False       False\n",
    "        \n",
    "        The value [4] will be True since, is the only one in which, the difference between trt[i] and \n",
    "        trt[i+1] is 1 \n",
    "\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame with the following columns\n",
    "        ['weight'   'trt'    'diff'    'tolerance'   'merge']\n",
    "        weight(index): weight value of the different patients\n",
    "        trt: treatment value\n",
    "        diff: difference between consecutive treatment values after sorting the DataFrame\n",
    "        tolerance:  if diff <= tolerance\n",
    "                        return True\n",
    "                    else\n",
    "                        return False\n",
    "        merge:  if (df['tolerance'] == True) & (shifted_index == df.index)\n",
    "                    return True\n",
    "                else\n",
    "                    return True\n",
    "        \n",
    "        shifted_index is the value of the index in the position [i+1] \n",
    "        \n",
    "        where: \n",
    "            i is the current index position \n",
    "        \n",
    "    '''\n",
    "    #Extract specific columns from the original DataFrame\n",
    "    df_spec_col = df[columns]\n",
    "    #Dictionary in which the indexes are the different trt values\n",
    "    df_dict = dict_trt(df_spec_col)\n",
    "    #DataFrame to evaluate weight with trt\n",
    "    df = trt_weight_vis(df_dict)\n",
    "    #DataFrame to evaluate which trt should be merged \n",
    "    df = trt_to_merge(df, tolerance)\n",
    "    \n",
    "    return df,df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86325d-e84e-4423-94c4-009a18e0932a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Part One</b> \n",
    "    <p>\n",
    "        <ul>\n",
    "        <li>DataFrame ['df_patients'] with information of the possible trt values to merge. This decision depends on the diff value; tolerance parameter.  </li>\n",
    "        <li>Dictionary ['df_dict_initial'] in which each key corresponds to the DataFrame of the respective trt number. The dictionary is a collection of DataFrames.</li>\n",
    "        </ul>\n",
    "             </p> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a870f96-a334-4a95-a19c-a5dca4dc62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns to consider from the original Data\n",
    "columns=[\"Date__Heure\",\"P_Access\",\"P_Filter\",\"P_Effluent\",\"P_Return\",\"Q_Blood_Pump\",\n",
    "          \"Q_Replacement\", \"Q_Dialysate\", \"Q_PBP\", \"DeltaP\", \"TMP\", \"TMPa\", \"trt\", \"Patient_weight__Kg_\", \"Set\"]\n",
    "df_patients, df_dict_initial = patient_recognition(df,columns,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792f9c8d-56bc-46e9-8835-103307d4889b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trt</th>\n",
       "      <th>diff</th>\n",
       "      <th>tolerance</th>\n",
       "      <th>merge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>833</td>\n",
       "      <td>56.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>889</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>905</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>915</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.0</th>\n",
       "      <td>911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.0</th>\n",
       "      <td>912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.0</th>\n",
       "      <td>913</td>\n",
       "      <td>110.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56.0</th>\n",
       "      <td>803</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56.0</th>\n",
       "      <td>853</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56.0</th>\n",
       "      <td>953</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        trt   diff  tolerance  merge\n",
       "weight                              \n",
       "50.0    833   56.0      False  False\n",
       "50.0    889   16.0      False  False\n",
       "50.0    905   10.0      False  False\n",
       "50.0    915    4.0      False  False\n",
       "55.0    911    1.0       True   True\n",
       "55.0    912    1.0       True   True\n",
       "55.0    913  110.0      False  False\n",
       "56.0    803   50.0      False  False\n",
       "56.0    853  100.0      False  False\n",
       "56.0    953   32.0      False  False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patients.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0879b21c-e118-4093-8345-e2a01c6a6223",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Part Two</b> \n",
    "    <p>\n",
    "        Dictionary ['dictionary_merge']  with the information of the trt to be merged. Form the previous DataFrame ['df_patients'], if merge == True, we join the current [i] and the next trt [i+1] as treatments to be merged\n",
    "    </p> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45cb669e-27bd-449d-9a8b-2afa522c2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_merge(df_patients):\n",
    "    '''The function returns a dictionary with the pair of treatments to merge\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_patients : pandas.core.frame.DataFrame\n",
    "        DataFrame with the columns\n",
    "         weight   trt    diff    tolerance   merge\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trt_merge_dict : dict\n",
    "        Dictionary with tuples corresponding to the trt values to merge\n",
    "        \n",
    "    '''\n",
    "    df = df_patients.reset_index()\n",
    "    indexes = df[df['merge'] == True].index.tolist()\n",
    "    trt_merge_dict = {}\n",
    "    \n",
    "    for i in range(len(indexes)):  \n",
    "        index_val = indexes[i]\n",
    "        trt_val = df['trt'][index_val]\n",
    "        dict_name = f\"index_{index_val}\"\n",
    "        new_trt_merge = {'index': index_val, 'trt': {trt_val,trt_val+1}}\n",
    "        trt_merge_dict.update({dict_name: new_trt_merge})\n",
    "    \n",
    "    #Sort dict according to 'trt'\n",
    "    sorted_data = dict(sorted(trt_merge_dict.items(), key=lambda item: min(item[1]['trt'])))\n",
    "    \n",
    "    # Convert 'trt' sets to sorted lists\n",
    "    for key in sorted_data:\n",
    "        sorted_data[key]['trt'] = sorted(sorted_data[key]['trt'])\n",
    "        \n",
    "    return sorted_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "406798b8-18a7-4340-97b2-bcc4d6093d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_30': {'index': 30, 'trt': [804, 805]},\n",
       " 'index_121': {'index': 121, 'trt': [817, 818]},\n",
       " 'index_52': {'index': 52, 'trt': [837, 838]},\n",
       " 'index_55': {'index': 55, 'trt': [842, 843]},\n",
       " 'index_56': {'index': 56, 'trt': [843, 844]},\n",
       " 'index_171': {'index': 171, 'trt': [847, 848]},\n",
       " 'index_59': {'index': 59, 'trt': [864, 865]},\n",
       " 'index_60': {'index': 60, 'trt': [865, 866]},\n",
       " 'index_61': {'index': 61, 'trt': [866, 867]},\n",
       " 'index_124': {'index': 124, 'trt': [874, 875]},\n",
       " 'index_125': {'index': 125, 'trt': [875, 876]},\n",
       " 'index_126': {'index': 126, 'trt': [876, 877]},\n",
       " 'index_65': {'index': 65, 'trt': [894, 895]},\n",
       " 'index_67': {'index': 67, 'trt': [899, 900]},\n",
       " 'index_4': {'index': 4, 'trt': [911, 912]},\n",
       " 'index_5': {'index': 5, 'trt': [912, 913]},\n",
       " 'index_43': {'index': 43, 'trt': [916, 917]},\n",
       " 'index_74': {'index': 74, 'trt': [935, 936]},\n",
       " 'index_75': {'index': 75, 'trt': [936, 937]},\n",
       " 'index_96': {'index': 96, 'trt': [946, 947]},\n",
       " 'index_97': {'index': 97, 'trt': [947, 948]},\n",
       " 'index_99': {'index': 99, 'trt': [950, 951]},\n",
       " 'index_102': {'index': 102, 'trt': [958, 959]},\n",
       " 'index_140': {'index': 140, 'trt': [964, 965]},\n",
       " 'index_93': {'index': 93, 'trt': [970, 971]},\n",
       " 'index_143': {'index': 143, 'trt': [972, 973]},\n",
       " 'index_148': {'index': 148, 'trt': [988, 989]},\n",
       " 'index_149': {'index': 149, 'trt': [989, 990]},\n",
       " 'index_154': {'index': 154, 'trt': [999, 1000]},\n",
       " 'index_155': {'index': 155, 'trt': [1000, 1001]},\n",
       " 'index_110': {'index': 110, 'trt': [1005, 1006]},\n",
       " 'index_111': {'index': 111, 'trt': [1006, 1007]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_merge_dict = dictionary_merge(df_patients)\n",
    "trt_merge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1dff5d1-aab8-4cbe-9d68-a4d18f6088bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>original_index</th>\n",
       "      <th>trt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index_30</td>\n",
       "      <td>30</td>\n",
       "      <td>[804, 805]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>index_121</td>\n",
       "      <td>121</td>\n",
       "      <td>[817, 818]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>index_52</td>\n",
       "      <td>52</td>\n",
       "      <td>[837, 838]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>index_55</td>\n",
       "      <td>55</td>\n",
       "      <td>[842, 843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>index_56</td>\n",
       "      <td>56</td>\n",
       "      <td>[843, 844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>index_171</td>\n",
       "      <td>171</td>\n",
       "      <td>[847, 848]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>index_59</td>\n",
       "      <td>59</td>\n",
       "      <td>[864, 865]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>index_60</td>\n",
       "      <td>60</td>\n",
       "      <td>[865, 866]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>index_61</td>\n",
       "      <td>61</td>\n",
       "      <td>[866, 867]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>index_124</td>\n",
       "      <td>124</td>\n",
       "      <td>[874, 875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>index_125</td>\n",
       "      <td>125</td>\n",
       "      <td>[875, 876]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>index_126</td>\n",
       "      <td>126</td>\n",
       "      <td>[876, 877]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>index_65</td>\n",
       "      <td>65</td>\n",
       "      <td>[894, 895]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>index_67</td>\n",
       "      <td>67</td>\n",
       "      <td>[899, 900]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>index_4</td>\n",
       "      <td>4</td>\n",
       "      <td>[911, 912]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0  original_index         trt\n",
       "0    index_30              30  [804, 805]\n",
       "1   index_121             121  [817, 818]\n",
       "2    index_52              52  [837, 838]\n",
       "3    index_55              55  [842, 843]\n",
       "4    index_56              56  [843, 844]\n",
       "5   index_171             171  [847, 848]\n",
       "6    index_59              59  [864, 865]\n",
       "7    index_60              60  [865, 866]\n",
       "8    index_61              61  [866, 867]\n",
       "9   index_124             124  [874, 875]\n",
       "10  index_125             125  [875, 876]\n",
       "11  index_126             126  [876, 877]\n",
       "12   index_65              65  [894, 895]\n",
       "13   index_67              67  [899, 900]\n",
       "14    index_4               4  [911, 912]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dictionary to a DataFrame\n",
    "df_dict = pd.DataFrame.from_dict(trt_merge_dict, orient='index')\n",
    "\n",
    "# Reset the index to have a default integer index and move the original index to a column\n",
    "df_dict.reset_index(inplace=True)\n",
    "\n",
    "# Rename the column for clarity\n",
    "df_dict.rename(columns={'index': 'original_index'}, inplace=True)\n",
    "df_dict.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacb9451-6eaa-45d1-853d-3fc30ebd7b40",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    At this point we found the problem that in some cases we have to merge more than 2 treatments. Consider as example, the iloc indexes, [8] and [9]\n",
    "    <li>[8] corresponds to the treatments [684, 685] which are treatments corresponding to the same patient, beacause of the weight value</li>\n",
    "    <li>[9] corresponds to the treatments [685, 686] which are treatments corresponding to the same patient, beacause of the weight value</li>\n",
    "    We have an intersection at the value 685, this means that treatments 684, 685, 686 potentially corresponds to the same patient. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86071f1b-8c85-4b4c-a000-4f01b8f4857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_compar(df, i):\n",
    "    '''The function compares the trt values looking for an intersection between two continuous rows. i.e., [0] and [1] \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame with the columns\n",
    "\n",
    "        level_0\t    original_index\t    trt\n",
    "    [0]\tindex_48\t     48\t         [608, 609]\n",
    "    [1]\tindex_4\t          4\t         [618, 619]\n",
    "    [2]\tindex_16\t     16\t         [624, 625]\n",
    "\n",
    "    i : iterator to go through the different rows of the DataFrame      \n",
    "    Returns\n",
    "    -------\n",
    "    True / False : boolean\n",
    "        Boolean with the result of the comparisson\n",
    "        \n",
    "    '''\n",
    "    value_01 = list(df_dict['trt'].iloc[i])[1]\n",
    "    value_02 = list(df_dict['trt'].iloc[i+1])[0]\n",
    "    if value_01 == value_02:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9ddd142-0f74-4d6d-b8b2-bc49fa5cdb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_multiple_merge(df_dict):\n",
    "    '''The function returns a dictionary with the list of all the merges we could potentially do. \n",
    "    This information was obtained according to the trt value and the patient's weight.\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dict : pandas.core.frame.DataFrame\n",
    "        DataFrame with the columns\n",
    "\n",
    "        level_0\t    original_index\t    trt\n",
    "    [0]\tindex_48\t     48\t         [608, 609]\n",
    "    [1]\tindex_4\t          4\t         [618, 619]\n",
    "    [2]\tindex_16\t     16\t         [624, 625]\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    dict : dict\n",
    "        Dictionary with the potential treatments to merge. We expect something like the following output\n",
    "        \n",
    "        {'index_48': {'values': [608, 609]},\n",
    "         'index_4': {'values': [618, 619]},\n",
    "         'index_16': {'values': [624, 625]},\n",
    "         'index_66': {'values': [632, 633]},\n",
    "         'index_90': {'values': [649, 650]},\n",
    "         'index_116': {'values': [660, 661]},\n",
    "         'index_119': {'values': [680, 681]},\n",
    "         'index_154': {'values': [682, 683]},\n",
    "         'index_142': {'values': ([684, 685], [685, 686])}, ...\n",
    "        \n",
    "    '''\n",
    "    dict={}\n",
    "    i=0\n",
    "    iter_range = len(df_dict)-1\n",
    "    #Given a DataFrame like the one from the example, we iterate through the whole list of trt values ['iter_range']\n",
    "    while i < iter_range:\n",
    "        result = trt_compar(df_dict,i)\n",
    "        list_trt = []\n",
    "        if result == True:\n",
    "            #Save the first tuple in a list\n",
    "            list_trt.append((df_dict['trt'].iloc[i],\n",
    "                       (df_dict['trt'].iloc[i+1])))\n",
    "            #Search more tuples to save in the list\n",
    "            for j in range(i+1,iter_range):\n",
    "                result = trt_compar(df_dict,j)\n",
    "                if result == True:\n",
    "                    list_trt.append([df_dict['trt'].iloc[j+1]])\n",
    "                else:\n",
    "                    diff = j-i\n",
    "                    i += diff\n",
    "                    break    \n",
    "    \n",
    "            list_name = f\"index_{df_dict['original_index'].iloc[i]}\"\n",
    "            list_merge = {'values': list_trt}\n",
    "            dict.update({list_name: list_merge})        \n",
    "        \n",
    "        else:\n",
    "            list_trt = list(df_dict['trt'].iloc[i])\n",
    "            list_name = f\"index_{df_dict['original_index'].iloc[i]}\"\n",
    "            list_merge = {'values': list_trt}\n",
    "            dict.update({list_name: list_merge})\n",
    "        i += 1\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9862c71a-4957-461d-b9e8-bcf644391a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = dictionary_multiple_merge(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cb46446-5e7c-40b6-a3f8-4e958f539796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_30': {'values': [804, 805]},\n",
       " 'index_121': {'values': [817, 818]},\n",
       " 'index_52': {'values': [837, 838]},\n",
       " 'index_56': {'values': [([842, 843], [843, 844])]},\n",
       " 'index_171': {'values': [847, 848]},\n",
       " 'index_61': {'values': [([864, 865], [865, 866]), [[866, 867]]]},\n",
       " 'index_126': {'values': [([874, 875], [875, 876]), [[876, 877]]]},\n",
       " 'index_65': {'values': [894, 895]},\n",
       " 'index_67': {'values': [899, 900]},\n",
       " 'index_5': {'values': [([911, 912], [912, 913])]},\n",
       " 'index_43': {'values': [916, 917]},\n",
       " 'index_75': {'values': [([935, 936], [936, 937])]},\n",
       " 'index_97': {'values': [([946, 947], [947, 948])]},\n",
       " 'index_99': {'values': [950, 951]},\n",
       " 'index_102': {'values': [958, 959]},\n",
       " 'index_140': {'values': [964, 965]},\n",
       " 'index_93': {'values': [970, 971]},\n",
       " 'index_143': {'values': [972, 973]},\n",
       " 'index_149': {'values': [([988, 989], [989, 990])]},\n",
       " 'index_155': {'values': [([999, 1000], [1000, 1001])]},\n",
       " 'index_110': {'values': [([1005, 1006], [1006, 1007])]}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c31a518-98ce-493d-8273-8d58d29162bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#Function to fix since is not producing the expected output\n",
    "def dictionary_multiple_merge_clean(dict, df_dict_initial):\n",
    "    '''The function returns a dictionary with the original DataFrames plus the DataFrames that potentially could be merged.\n",
    "    The dictionary is a collection of DataFrames\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dict : dict \n",
    "        dictionary with the values to merge. We expect something like the following input \n",
    "           {'index_48': {'values': [608, 609]},\n",
    "             'index_4': {'values': [618, 619]},\n",
    "             'index_16': {'values': [624, 625]},\n",
    "             'index_66': {'values': [632, 633]},\n",
    "             'index_90': {'values': [649, 650]},\n",
    "             'index_116': {'values': [660, 661]},\n",
    "             'index_119': {'values': [680, 681]},\n",
    "             'index_154': {'values': [682, 683]},\n",
    "             'index_142': {'values': ([684, 685], [685, 686])},   \n",
    "           \n",
    "    df_dict_initial : dict\n",
    "        initial dictionary in which each key corresponds to a different treatment 'trt' value\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_dict_initial_clean : dict\n",
    "        dictionary in which each key corresponds to a single or a merged DataFrame\n",
    "        \n",
    "    '''\n",
    "    for key, value in dict.items():\n",
    "        values = value['values']\n",
    "        # If values is a tuple, combine the inner lists into a single list\n",
    "        if isinstance(values, tuple):\n",
    "            combined_values = []\n",
    "            for sublist in values:\n",
    "                combined_values.extend(sublist)\n",
    "            values = combined_values\n",
    "        # Remove duplicates from the list\n",
    "        values = remove_duplicates(values)\n",
    "        # Add prefix \"df_\" to each element in the list\n",
    "        values = [f\"df_{v}\" for v in values]\n",
    "        #Merge the DataFrames\n",
    "        concat_df = pd.concat([df_dict_initial[key] for key in values], axis=0)\n",
    "        values_str = '-'.join(values)\n",
    "        name = f'{values_str}-concat'\n",
    "        df_dict_initial[name] = concat_df\n",
    "        return df_dict_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78eb7327-de88-4e36-b723-50e6177985e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('index_30', {'values': [804, 805]}), ('index_121', {'values': [817, 818]}), ('index_52', {'values': [837, 838]}), ('index_56', {'values': [([842, 843], [843, 844])]}), ('index_171', {'values': [847, 848]}), ('index_61', {'values': [([864, 865], [865, 866]), [[866, 867]]]}), ('index_126', {'values': [([874, 875], [875, 876]), [[876, 877]]]}), ('index_65', {'values': [894, 895]}), ('index_67', {'values': [899, 900]}), ('index_5', {'values': [([911, 912], [912, 913])]}), ('index_43', {'values': [916, 917]}), ('index_75', {'values': [([935, 936], [936, 937])]}), ('index_97', {'values': [([946, 947], [947, 948])]}), ('index_99', {'values': [950, 951]}), ('index_102', {'values': [958, 959]}), ('index_140', {'values': [964, 965]}), ('index_93', {'values': [970, 971]}), ('index_143', {'values': [972, 973]}), ('index_149', {'values': [([988, 989], [989, 990])]}), ('index_155', {'values': [([999, 1000], [1000, 1001])]}), ('index_110', {'values': [([1005, 1006], [1006, 1007])]})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ba6124-1e26-4730-9478-6dc70b4730a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    \"\"\"Recursively flatten a nested list or tuple.\"\"\"\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            flat_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "def remove_duplicates(input_list):\n",
    "    \"\"\"Remove duplicates from a list while maintaining order.\"\"\"\n",
    "    unique_list = []\n",
    "    seen = set()\n",
    "    for item in input_list:\n",
    "        if item not in seen:\n",
    "            unique_list.append(item)\n",
    "            seen.add(item)\n",
    "    return unique_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f395c2-2717-4a21-ba0a-7581af56e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the final dictionary. Each key is a DataFrame; at the end we appended those corresponding to potentially merges\n",
    "\n",
    "for key, value in dict.items():\n",
    "    values = value['values']\n",
    "    # If values is a tuple, combine the inner lists into a single list\n",
    "    if isinstance(values, tuple):\n",
    "        combined_values = []\n",
    "        for sublist in values:\n",
    "            combined_values.extend(sublist)\n",
    "        values = combined_values\n",
    "    # Remove duplicates from the list\n",
    "    values = flatten_list(values)\n",
    "    values = remove_duplicates(values)\n",
    "    # Add prefix \"df_\" to each element in the list\n",
    "    values = [f\"df_{v}\" for v in values]\n",
    "    #Merge the DataFrames\n",
    "    concat_df = pd.concat([df_dict_initial[key] for key in values], axis=0)\n",
    "    values_str = '-'.join(values)\n",
    "    name = f'{values_str}-concat'\n",
    "    df_dict_initial[name] = concat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f69aa3e6-7613-45a1-95c6-fd8239346be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_801', 'df_802', 'df_803', 'df_804', 'df_805', 'df_806', 'df_807', 'df_808', 'df_809', 'df_810', 'df_811', 'df_812', 'df_813', 'df_814', 'df_815', 'df_816', 'df_817', 'df_818', 'df_819', 'df_820', 'df_821', 'df_822', 'df_823', 'df_824', 'df_825', 'df_826', 'df_827', 'df_828', 'df_829', 'df_830', 'df_831', 'df_832', 'df_833', 'df_834', 'df_835', 'df_836', 'df_837', 'df_838', 'df_839', 'df_840', 'df_841', 'df_842', 'df_843', 'df_844', 'df_845', 'df_846', 'df_847', 'df_848', 'df_849', 'df_850', 'df_851', 'df_853', 'df_854', 'df_855', 'df_856', 'df_857', 'df_858', 'df_859', 'df_860', 'df_861', 'df_862', 'df_863', 'df_864', 'df_865', 'df_866', 'df_867', 'df_868', 'df_869', 'df_870', 'df_871', 'df_872', 'df_873', 'df_874', 'df_875', 'df_876', 'df_877', 'df_878', 'df_879', 'df_880', 'df_881', 'df_882', 'df_883', 'df_884', 'df_885', 'df_886', 'df_887', 'df_888', 'df_889', 'df_891', 'df_892', 'df_893', 'df_894', 'df_895', 'df_896', 'df_897', 'df_898', 'df_899', 'df_900', 'df_901', 'df_902', 'df_903', 'df_904', 'df_905', 'df_906', 'df_907', 'df_908', 'df_909', 'df_910', 'df_911', 'df_912', 'df_913', 'df_914', 'df_915', 'df_916', 'df_917', 'df_918', 'df_919', 'df_920', 'df_921', 'df_922', 'df_923', 'df_924', 'df_925', 'df_926', 'df_927', 'df_928', 'df_929', 'df_930', 'df_932', 'df_933', 'df_935', 'df_936', 'df_937', 'df_939', 'df_940', 'df_941', 'df_942', 'df_943', 'df_944', 'df_945', 'df_946', 'df_947', 'df_948', 'df_949', 'df_950', 'df_951', 'df_952', 'df_953', 'df_954', 'df_955', 'df_956', 'df_957', 'df_958', 'df_959', 'df_960', 'df_961', 'df_962', 'df_963', 'df_964', 'df_965', 'df_966', 'df_967', 'df_968', 'df_969', 'df_970', 'df_971', 'df_972', 'df_973', 'df_974', 'df_975', 'df_976', 'df_977', 'df_978', 'df_979', 'df_980', 'df_981', 'df_982', 'df_983', 'df_984', 'df_985', 'df_986', 'df_987', 'df_988', 'df_989', 'df_990', 'df_991', 'df_992', 'df_993', 'df_994', 'df_995', 'df_996', 'df_997', 'df_998', 'df_999', 'df_1000', 'df_1001', 'df_1002', 'df_1003', 'df_1004', 'df_1005', 'df_1006', 'df_1007', 'df_804-df_805-concat', 'df_817-df_818-concat', 'df_837-df_838-concat', 'df_842-df_843-df_844-concat', 'df_847-df_848-concat', 'df_864-df_865-df_866-df_867-concat', 'df_874-df_875-df_876-df_877-concat', 'df_894-df_895-concat', 'df_899-df_900-concat', 'df_911-df_912-df_913-concat', 'df_916-df_917-concat', 'df_935-df_936-df_937-concat', 'df_946-df_947-df_948-concat', 'df_950-df_951-concat', 'df_958-df_959-concat', 'df_964-df_965-concat', 'df_970-df_971-concat', 'df_972-df_973-concat', 'df_988-df_989-df_990-concat', 'df_999-df_1000-df_1001-concat', 'df_1005-df_1006-df_1007-concat'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict_initial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74f4bb-ce7f-4963-85dc-427fa8f76c7c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  <p>\n",
    "    <b>Evaluation of the results</b>\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    \n",
    "\n",
    "  </p>\n",
    "    \n",
    "  <p>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4aa8cdfb-5d84-4b3f-99a6-2136604deba1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#Lets see how the time stamp of different trt that should be merged is set\n",
    "df_01 = df_dict_initial['df_759']\n",
    "df_02 = df_dict_initial['df_760']\n",
    "df_03 = df_dict_initial['df_761']\n",
    "df_01.head()\n",
    "df_02.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571a4b4-22d5-40ab-95f7-e2aee6b456f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  <p>\n",
    "    <b>Remark</b>\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    The trt values does not, necessarly, correspond to a new series of data. In some cases many of the values are repeated.\n",
    "    Lines of action:\n",
    "      <ul>\n",
    "            <li>Clean repeat information</li>\n",
    "      </ul>\n",
    "\n",
    "  </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcda7df-1c18-49da-8490-2967d6eb4c1c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    " <p>\n",
    "    The following function does a comparision only when we are considering 2 DataFrames. When we are considering more than 2 DataFrames, it just merge them. For the nature of the data is very unlikley that 3 potentially DataFrames, or more, to merge are not corresponding to the same patient. Anyway after the merge we can compare the difference between the first timestamp of information and the last one. \n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79c239fc-7702-4917-87c2-623d88f2bac2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "'''Function to see if the potentially DataFrames are close enough, according to the timestamp, so we can merge them. days indicates the maximum tolerance \n",
    "allowed between DataFrames'''\n",
    "#We can use the merge DataFrames directly, and compare the first and the last row of the timestamp. If the tolerance is satisfied we delete the original ones\n",
    "#otherwise, we keep them and delete the concat DataFrame\n",
    "\n",
    "days=5\n",
    "delete_elements=[]\n",
    "\n",
    "for name in df_dict_initial.keys():\n",
    "    if 'concat' in name:\n",
    "        # Remove '_concat' part\n",
    "        base_part = name.replace('-concat', '')\n",
    "        # Split the remaining part to get the variables\n",
    "        parts = base_part.split('-')\n",
    "        if len(parts) == 2:\n",
    "            name_01 = parts[0]\n",
    "            name_02 = parts[1]\n",
    "            #Load the DataFrames\n",
    "            df_01 = df_dict_initial[name_01]\n",
    "            df_02 = df_dict_initial[name_02]\n",
    "            # Print the variables\n",
    "            date_01 = df_01[\"Date__Heure\"].iloc[0]\n",
    "            date_02 = df_02[\"Date__Heure\"].iloc[0]\n",
    "            decision = abs(date_02 - date_01) <= pd.Timedelta(days=days)\n",
    "            #if decision is true we need to merge the DataFrames otherwise DataFrames keep the same\n",
    "            #the DataFrames are already merged we just need to cut from df_dict_initial the merged DataFrame or the\n",
    "            #individual ones\n",
    "            if decision == True:\n",
    "                #Delete the individual DataFrames from df_dict_initial\n",
    "                delete_elements.append(name_01)\n",
    "                delete_elements.append(name_02)\n",
    "            else:\n",
    "                #Delete the merged DataFrame\n",
    "                delete_elements.append(name)\n",
    "        else:\n",
    "            for item in parts:\n",
    "                delete_elements.append(item)\n",
    "        \n",
    "for item in delete_elements:\n",
    "    del df_dict_initial[item]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c75178f-c693-4821-97a3-7c131950d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function to see if the potentially DataFrames are close enough, according to the timestamp, so we can merge them. days indicates the maximum tolerance \n",
    "allowed between DataFrames'''\n",
    "days = 5\n",
    "delete_elements=[]\n",
    "\n",
    "for dframe in df_dict_initial.keys():\n",
    "    if 'concat' in dframe:\n",
    "        df_test = df_dict_initial[dframe]\n",
    "        initial = df_test[\"Date__Heure\"].iloc[0]\n",
    "        final = df_test[\"Date__Heure\"].iloc[-1]\n",
    "        decision = abs(initial - final) <= pd.Timedelta(days=days)\n",
    "        if decision == True:\n",
    "            #Delete individual DataFrames\n",
    "            base_part = dframe.replace('-concat', '')\n",
    "            parts = base_part.split('-')\n",
    "            for item in parts:\n",
    "                delete_elements.append(item) \n",
    "        else:\n",
    "            #Delete merge DataFrames\n",
    "            delete_elements.append(dframe)\n",
    "\n",
    "for element in delete_elements:\n",
    "    del df_dict_initial[element] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cbdc359-4ca0-4919-bad3-5aa3c10b2ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_801', 'df_802', 'df_803', 'df_806', 'df_807', 'df_808', 'df_809', 'df_810', 'df_811', 'df_812', 'df_813', 'df_814', 'df_815', 'df_816', 'df_817', 'df_818', 'df_819', 'df_820', 'df_821', 'df_822', 'df_823', 'df_824', 'df_825', 'df_826', 'df_827', 'df_828', 'df_829', 'df_830', 'df_831', 'df_832', 'df_833', 'df_834', 'df_835', 'df_836', 'df_839', 'df_840', 'df_841', 'df_842', 'df_843', 'df_844', 'df_845', 'df_846', 'df_849', 'df_850', 'df_851', 'df_853', 'df_854', 'df_855', 'df_856', 'df_857', 'df_858', 'df_859', 'df_860', 'df_861', 'df_862', 'df_863', 'df_868', 'df_869', 'df_870', 'df_871', 'df_872', 'df_873', 'df_874', 'df_875', 'df_876', 'df_877', 'df_878', 'df_879', 'df_880', 'df_881', 'df_882', 'df_883', 'df_884', 'df_885', 'df_886', 'df_887', 'df_888', 'df_889', 'df_891', 'df_892', 'df_893', 'df_894', 'df_895', 'df_896', 'df_897', 'df_898', 'df_899', 'df_900', 'df_901', 'df_902', 'df_903', 'df_904', 'df_905', 'df_906', 'df_907', 'df_908', 'df_909', 'df_910', 'df_914', 'df_915', 'df_918', 'df_919', 'df_920', 'df_921', 'df_922', 'df_923', 'df_924', 'df_925', 'df_926', 'df_927', 'df_928', 'df_929', 'df_930', 'df_932', 'df_933', 'df_935', 'df_936', 'df_937', 'df_939', 'df_940', 'df_941', 'df_942', 'df_943', 'df_944', 'df_945', 'df_946', 'df_947', 'df_948', 'df_949', 'df_950', 'df_951', 'df_952', 'df_953', 'df_954', 'df_955', 'df_956', 'df_957', 'df_958', 'df_959', 'df_960', 'df_961', 'df_962', 'df_963', 'df_964', 'df_965', 'df_966', 'df_967', 'df_968', 'df_969', 'df_974', 'df_975', 'df_976', 'df_977', 'df_978', 'df_979', 'df_980', 'df_981', 'df_982', 'df_983', 'df_984', 'df_985', 'df_986', 'df_987', 'df_991', 'df_992', 'df_993', 'df_994', 'df_995', 'df_996', 'df_997', 'df_998', 'df_1002', 'df_1003', 'df_1004', 'df_804-df_805-concat', 'df_837-df_838-concat', 'df_847-df_848-concat', 'df_864-df_865-df_866-df_867-concat', 'df_911-df_912-df_913-concat', 'df_916-df_917-concat', 'df_970-df_971-concat', 'df_972-df_973-concat', 'df_988-df_989-df_990-concat', 'df_999-df_1000-df_1001-concat', 'df_1005-df_1006-df_1007-concat'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''At this point df_dict_initial contains DataFrames corresponding to a single treatment in \n",
    "case the previous merged conditions were not satisfied or a merged DataFrame in the opposite case.\n",
    "If the DataFrames were merged, the original ones were deleted'''\n",
    "df_dict_initial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac0fbf-7dde-4d00-8654-7d5f4c70794a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  <p>\n",
    "    <b>How to save this DataFrames?</b>\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    <li>Will depend on how we are going to use them for the model deployment</li> \n",
    "    \n",
    "\n",
    "  </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd8de972-b7e5-41c1-9f0c-dd65160068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For quality control, we can verify the first and the last row of the concat DataFrames and see if the difference is not bigger than 3 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79eee480-0595-4bea-baf0-dfa7a31c7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_control(df_dict,days):\n",
    "    '''The function is a quality control check to see if the difference between the intial and the last timestamp is not considerably big.\n",
    "    We expect to have a difference of days because of the nature of the data.\n",
    "\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dict : dict \n",
    "        dictionary in which each key is a DataFrame\n",
    "    days : int\n",
    "        tolerance in days\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None : list\n",
    "        the function prints 'Error + DataFrame name' i.e., 'Error df_601' if a DataFrame does not meet the given tolerance\n",
    "        \n",
    "    '''\n",
    "    for dframe in df_dict.keys():\n",
    "        df_test = df_dict[dframe]\n",
    "        initial = df_test[\"Date__Heure\"].iloc[0]\n",
    "        final = df_test[\"Date__Heure\"].iloc[-1]\n",
    "        decision = abs(initial - final) <= pd.Timedelta(days=days)\n",
    "        if decision == False:\n",
    "            print(f'Error {dframe}')\n",
    "        else:\n",
    "            continue\n",
    "    print('If no message was displayed before this, the quality control was passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9984fbf-2f41-4afe-b715-2db1e78e6879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date__Heure</th>\n",
       "      <th>P_Access</th>\n",
       "      <th>P_Filter</th>\n",
       "      <th>P_Effluent</th>\n",
       "      <th>P_Return</th>\n",
       "      <th>Q_Blood_Pump</th>\n",
       "      <th>Q_Replacement</th>\n",
       "      <th>Q_Dialysate</th>\n",
       "      <th>Q_PBP</th>\n",
       "      <th>DeltaP</th>\n",
       "      <th>TMP</th>\n",
       "      <th>TMPa</th>\n",
       "      <th>trt</th>\n",
       "      <th>Patient_weight__Kg_</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-07-28 22:58:00</td>\n",
       "      <td>54</td>\n",
       "      <td>-25</td>\n",
       "      <td>-26</td>\n",
       "      <td>-38</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>-12</td>\n",
       "      <td>-23.5</td>\n",
       "      <td>-29</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-07-28 22:59:00</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>-13</td>\n",
       "      <td>33</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>-1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-07-28 23:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>94</td>\n",
       "      <td>-1</td>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>65</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-07-28 23:01:00</td>\n",
       "      <td>27</td>\n",
       "      <td>121</td>\n",
       "      <td>28</td>\n",
       "      <td>95</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-07-28 23:02:00</td>\n",
       "      <td>6</td>\n",
       "      <td>112</td>\n",
       "      <td>19</td>\n",
       "      <td>72</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>15</td>\n",
       "      <td>55.0</td>\n",
       "      <td>63</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-07-28 23:03:00</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>11</td>\n",
       "      <td>68</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>16</td>\n",
       "      <td>59.5</td>\n",
       "      <td>68</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-07-28 23:04:00</td>\n",
       "      <td>6</td>\n",
       "      <td>115</td>\n",
       "      <td>14</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>15</td>\n",
       "      <td>63.0</td>\n",
       "      <td>71</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-07-28 23:05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>17</td>\n",
       "      <td>72</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>15</td>\n",
       "      <td>57.0</td>\n",
       "      <td>65</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011-07-28 23:06:00</td>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>16</td>\n",
       "      <td>74</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>14</td>\n",
       "      <td>59.5</td>\n",
       "      <td>67</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011-07-28 23:07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>26</td>\n",
       "      <td>48.5</td>\n",
       "      <td>62</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date__Heure  P_Access  P_Filter  P_Effluent  P_Return  Q_Blood_Pump  \\\n",
       "0 2011-07-28 22:58:00        54       -25         -26       -38           120   \n",
       "1 2011-07-28 22:59:00         7        57         -13        33           120   \n",
       "2 2011-07-28 23:00:00         7        94          -1        60           120   \n",
       "3 2011-07-28 23:01:00        27       121          28        95           120   \n",
       "4 2011-07-28 23:02:00         6       112          19        72           120   \n",
       "5 2011-07-28 23:03:00         3       109          11        68           120   \n",
       "6 2011-07-28 23:04:00         6       115          14        75           120   \n",
       "7 2011-07-28 23:05:00         3       112          17        72           120   \n",
       "8 2011-07-28 23:06:00         2       113          16        74           120   \n",
       "9 2011-07-28 23:07:00         0       106          14        55           120   \n",
       "\n",
       "   Q_Replacement  Q_Dialysate  Q_PBP  DeltaP   TMP  TMPa  trt  \\\n",
       "0           1200         2000   1200     -12 -23.5   -29  801   \n",
       "1           1200         2000   1200      -1  40.0    40  801   \n",
       "2           1200         2000   1200       9  60.0    65  801   \n",
       "3           1200         2000   1200       1  62.0    63  801   \n",
       "4           1200         2000   1200      15  55.0    63  801   \n",
       "5           1200         2000   1200      16  59.5    68  801   \n",
       "6           1200         2000   1200      15  63.0    71  801   \n",
       "7           1200         2000   1200      15  57.0    65  801   \n",
       "8           1200         2000   1200      14  59.5    67  801   \n",
       "9           1200         2000   1200      26  48.5    62  801   \n",
       "\n",
       "   Patient_weight__Kg_    Set  \n",
       "0                170.0  ST150  \n",
       "1                170.0  ST150  \n",
       "2                170.0  ST150  \n",
       "3                170.0  ST150  \n",
       "4                170.0  ST150  \n",
       "5                170.0  ST150  \n",
       "6                170.0  ST150  \n",
       "7                170.0  ST150  \n",
       "8                170.0  ST150  \n",
       "9                170.0  ST150  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_dict_initial['df_801']\n",
    "df_test.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cb96010-32a4-4dcd-b8fd-1be0bf45404c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date__Heure</th>\n",
       "      <th>P_Access</th>\n",
       "      <th>P_Filter</th>\n",
       "      <th>P_Effluent</th>\n",
       "      <th>P_Return</th>\n",
       "      <th>Q_Blood_Pump</th>\n",
       "      <th>Q_Replacement</th>\n",
       "      <th>Q_Dialysate</th>\n",
       "      <th>Q_PBP</th>\n",
       "      <th>DeltaP</th>\n",
       "      <th>TMP</th>\n",
       "      <th>TMPa</th>\n",
       "      <th>trt</th>\n",
       "      <th>Patient_weight__Kg_</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>2011-07-30 10:04:00</td>\n",
       "      <td>-18</td>\n",
       "      <td>174</td>\n",
       "      <td>-304</td>\n",
       "      <td>53</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>96</td>\n",
       "      <td>399.5</td>\n",
       "      <td>448</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>2011-07-30 10:05:00</td>\n",
       "      <td>-11</td>\n",
       "      <td>175</td>\n",
       "      <td>-312</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>80</td>\n",
       "      <td>416.5</td>\n",
       "      <td>457</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>2011-07-30 10:06:00</td>\n",
       "      <td>-10</td>\n",
       "      <td>196</td>\n",
       "      <td>-108</td>\n",
       "      <td>98</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>73</td>\n",
       "      <td>237.0</td>\n",
       "      <td>274</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>2011-07-30 10:07:00</td>\n",
       "      <td>-13</td>\n",
       "      <td>180</td>\n",
       "      <td>-278</td>\n",
       "      <td>78</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>77</td>\n",
       "      <td>389.0</td>\n",
       "      <td>428</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>2011-07-30 10:08:00</td>\n",
       "      <td>-17</td>\n",
       "      <td>171</td>\n",
       "      <td>-288</td>\n",
       "      <td>71</td>\n",
       "      <td>120</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1200</td>\n",
       "      <td>75</td>\n",
       "      <td>391.0</td>\n",
       "      <td>429</td>\n",
       "      <td>801</td>\n",
       "      <td>170.0</td>\n",
       "      <td>ST150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date__Heure  P_Access  P_Filter  P_Effluent  P_Return  \\\n",
       "2106 2011-07-30 10:04:00       -18       174        -304        53   \n",
       "2107 2011-07-30 10:05:00       -11       175        -312        70   \n",
       "2108 2011-07-30 10:06:00       -10       196        -108        98   \n",
       "2109 2011-07-30 10:07:00       -13       180        -278        78   \n",
       "2110 2011-07-30 10:08:00       -17       171        -288        71   \n",
       "\n",
       "      Q_Blood_Pump  Q_Replacement  Q_Dialysate  Q_PBP  DeltaP    TMP  TMPa  \\\n",
       "2106           120           1200         2000   1200      96  399.5   448   \n",
       "2107           120           1200         2000   1200      80  416.5   457   \n",
       "2108           120           1200         2000   1200      73  237.0   274   \n",
       "2109           120           1200         2000   1200      77  389.0   428   \n",
       "2110           120           1200         2000   1200      75  391.0   429   \n",
       "\n",
       "      trt  Patient_weight__Kg_    Set  \n",
       "2106  801                170.0  ST150  \n",
       "2107  801                170.0  ST150  \n",
       "2108  801                170.0  ST150  \n",
       "2109  801                170.0  ST150  \n",
       "2110  801                170.0  ST150  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddf28c15-11c1-431c-aa24-d0853769c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to save the final dictionary and see if we can open it in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "257c920f-3977-48d5-94b1-1593c8eb9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_no_ext = os.path.splitext(file)[0]\n",
    "name_save = f'{path_to_save}/{file_no_ext}.pkl' \n",
    "with open(name_save, 'wb') as file:\n",
    "    pickle.dump(df_dict_initial, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "853f224a-2237-43ed-b6e6-f5ca947ed318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/luisescobar/Documents/Thesis/DataSets/Dictionary/completo1007_(edit).pkl'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0f84e-230f-49e2-9ba8-c7c4659d59f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
