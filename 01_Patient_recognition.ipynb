{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c0c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the corresponding libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c080d6c-85bf-4a1a-b9bb-42ebd9cccd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Apache Parquet DataSet\n",
    "'''\n",
    "Each of the files for this project contains 2 tabs. For instance:\n",
    "The file completo800_(edit).xlsx contains the tabs:\n",
    "\n",
    "* totale\n",
    "* Foglio 1\n",
    "\n",
    "For performance reasons the original .xlsx files were converted to Apache_Parquet files\n",
    "After this transformation the only remainig tab is\n",
    "\n",
    "* totale\n",
    "\n",
    "which contains all the data concerning to the research\n",
    "''' \n",
    "#DataFrame used for deployment\n",
    "# '/Users/luisescobar/Documents/Thesis/DataSets/Apache_parquet/completo_800_output_file.parquet'\n",
    "\n",
    "path_to_read = '/Users/luisescobar/Documents/Thesis/DataSets/Apache_parquet'\n",
    "path_to_save = '/Users/luisescobar/Documents/Thesis/DataSets/Dictionary'\n",
    "file = 'completo_800_output_file.parquet'\n",
    "name_read = f'{path_to_read}/{file}'\n",
    "df = pd.read_parquet(name_read, engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4936df-1a2f-42cd-b04c-3a85618a44ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Date__Heure</th>\n",
       "      <th>P_Access</th>\n",
       "      <th>P_Filter</th>\n",
       "      <th>P_Effluent</th>\n",
       "      <th>P_Return</th>\n",
       "      <th>FIFTH_PRESSURE</th>\n",
       "      <th>RUN_TIME</th>\n",
       "      <th>Post_Replacement</th>\n",
       "      <th>Pre_Replacement</th>\n",
       "      <th>...</th>\n",
       "      <th>Citric_Acid_Concentration__mmol_</th>\n",
       "      <th>Citrate_Dose__mmol_L_</th>\n",
       "      <th>Calcium_Compensation____</th>\n",
       "      <th>Calcium_syringe_Concentration__m</th>\n",
       "      <th>Treatment_Duration__h_</th>\n",
       "      <th>effluent2</th>\n",
       "      <th>delta_eff</th>\n",
       "      <th>max_line</th>\n",
       "      <th>reverse</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-12 21:41:00</td>\n",
       "      <td>-9</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>-10</td>\n",
       "      <td>78951</td>\n",
       "      <td>12731</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>19.098612</td>\n",
       "      <td>49518</td>\n",
       "      <td>-40</td>\n",
       "      <td>2608</td>\n",
       "      <td>1156</td>\n",
       "      <td>-41843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-12 21:42:00</td>\n",
       "      <td>-14</td>\n",
       "      <td>88</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>-10</td>\n",
       "      <td>79011</td>\n",
       "      <td>12741</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>19.098612</td>\n",
       "      <td>49557</td>\n",
       "      <td>-39</td>\n",
       "      <td>2608</td>\n",
       "      <td>1155</td>\n",
       "      <td>-41803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-12 21:43:00</td>\n",
       "      <td>-16</td>\n",
       "      <td>125</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>-9</td>\n",
       "      <td>79071</td>\n",
       "      <td>12751</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>19.098612</td>\n",
       "      <td>49595</td>\n",
       "      <td>-38</td>\n",
       "      <td>2608</td>\n",
       "      <td>1154</td>\n",
       "      <td>-41764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-12 21:44:00</td>\n",
       "      <td>-13</td>\n",
       "      <td>123</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>-9</td>\n",
       "      <td>79131</td>\n",
       "      <td>12762</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>19.098612</td>\n",
       "      <td>49634</td>\n",
       "      <td>-39</td>\n",
       "      <td>2608</td>\n",
       "      <td>1153</td>\n",
       "      <td>-41726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-12 21:45:00</td>\n",
       "      <td>-15</td>\n",
       "      <td>117</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>-9</td>\n",
       "      <td>79191</td>\n",
       "      <td>12771</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>19.098612</td>\n",
       "      <td>49673</td>\n",
       "      <td>-39</td>\n",
       "      <td>2608</td>\n",
       "      <td>1152</td>\n",
       "      <td>-41687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient         Date__Heure  P_Access  P_Filter  P_Effluent  P_Return  \\\n",
       "0      NaN 2012-05-12 21:41:00        -9        60          21        23   \n",
       "1      NaN 2012-05-12 21:42:00       -14        88          24        32   \n",
       "2      NaN 2012-05-12 21:43:00       -16       125          66        61   \n",
       "3      NaN 2012-05-12 21:44:00       -13       123          66        63   \n",
       "4      NaN 2012-05-12 21:45:00       -15       117          58        58   \n",
       "\n",
       "   FIFTH_PRESSURE  RUN_TIME  Post_Replacement  Pre_Replacement  ...  \\\n",
       "0             -10     78951             12731                0  ...   \n",
       "1             -10     79011             12741                0  ...   \n",
       "2              -9     79071             12751                0  ...   \n",
       "3              -9     79131             12762                0  ...   \n",
       "4              -9     79191             12771                0  ...   \n",
       "\n",
       "   Citric_Acid_Concentration__mmol_  Citrate_Dose__mmol_L_  \\\n",
       "0                                 _                      _   \n",
       "1                                 _                      _   \n",
       "2                                 _                      _   \n",
       "3                                 _                      _   \n",
       "4                                 _                      _   \n",
       "\n",
       "   Calcium_Compensation____  Calcium_syringe_Concentration__m  \\\n",
       "0                         _                                 _   \n",
       "1                         _                                 _   \n",
       "2                         _                                 _   \n",
       "3                         _                                 _   \n",
       "4                         _                                 _   \n",
       "\n",
       "   Treatment_Duration__h_  effluent2  delta_eff  max_line  reverse    sum  \n",
       "0               19.098612      49518        -40      2608     1156 -41843  \n",
       "1               19.098612      49557        -39      2608     1155 -41803  \n",
       "2               19.098612      49595        -38      2608     1154 -41764  \n",
       "3               19.098612      49634        -39      2608     1153 -41726  \n",
       "4               19.098612      49673        -39      2608     1152 -41687  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abee5dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 311232 entries, 0 to 311231\n",
      "Data columns (total 94 columns):\n",
      " #   Column                            Non-Null Count   Dtype         \n",
      "---  ------                            --------------   -----         \n",
      " 0   Patient                           0 non-null       float64       \n",
      " 1   Date__Heure                       311232 non-null  datetime64[ns]\n",
      " 2   P_Access                          311232 non-null  int64         \n",
      " 3   P_Filter                          311232 non-null  int64         \n",
      " 4   P_Effluent                        311232 non-null  int64         \n",
      " 5   P_Return                          311232 non-null  int64         \n",
      " 6   FIFTH_PRESSURE                    311232 non-null  int64         \n",
      " 7   RUN_TIME                          311232 non-null  int64         \n",
      " 8   Post_Replacement                  311232 non-null  int64         \n",
      " 9   Pre_Replacement                   311232 non-null  int64         \n",
      " 10  Dialysate                         311232 non-null  int64         \n",
      " 11  Effluent                          311232 non-null  int64         \n",
      " 12  Pre_Blood_Pump                    311232 non-null  int64         \n",
      " 13  SYRINGE_INF                       311232 non-null  int64         \n",
      " 14  EXCESS_PT_FLUID                   311232 non-null  int64         \n",
      " 15  PUMP_PBP                          311232 non-null  float64       \n",
      " 16  PUMP_Rep                          311232 non-null  float64       \n",
      " 17  PUMP_Dial                         311232 non-null  float64       \n",
      " 18  PUMP_Eff                          311232 non-null  float64       \n",
      " 19  Q_Blood_Pump                      311232 non-null  int64         \n",
      " 20  Q_Replacement                     311232 non-null  int64         \n",
      " 21  Q_Dialysate                       311232 non-null  int64         \n",
      " 22  Q_PBP                             311232 non-null  int64         \n",
      " 23  Q_Patient_Fluid_Removal           311232 non-null  int64         \n",
      " 24  Patient_Fluid_Removal             311232 non-null  int64         \n",
      " 25  DeltaP                            311232 non-null  int64         \n",
      " 26  TMP                               311232 non-null  float64       \n",
      " 27  TMPa                              311232 non-null  int64         \n",
      " 28  Q_Effluent                        311232 non-null  int64         \n",
      " 29  Ratio                             311232 non-null  int64         \n",
      " 30  Q_syringe                         311232 non-null  float64       \n",
      " 31  Q_syringe_Calcium                 311232 non-null  float64       \n",
      " 32  Citrate_Dose                      311232 non-null  float64       \n",
      " 33  Calcium_Comp                      311232 non-null  int64         \n",
      " 34  F35                               0 non-null       float64       \n",
      " 35  F36                               0 non-null       float64       \n",
      " 36  F37                               0 non-null       float64       \n",
      " 37  F38                               0 non-null       float64       \n",
      " 38  F39                               0 non-null       float64       \n",
      " 39  F40                               0 non-null       float64       \n",
      " 40  F41                               0 non-null       float64       \n",
      " 41  trt                               311232 non-null  int64         \n",
      " 42  line                              311232 non-null  int64         \n",
      " 43  F1                                311232 non-null  int64         \n",
      " 44  F2                                311232 non-null  int64         \n",
      " 45  Patient_weight__Kg_               302326 non-null  float64       \n",
      " 46  Therapy                           311232 non-null  object        \n",
      " 47  Anticoagulation_selected_         311232 non-null  object        \n",
      " 48  Qb__mL_min_                       311232 non-null  int64         \n",
      " 49  Qpbp__ml_h_                       311232 non-null  int64         \n",
      " 50  Qd__ml_h_                         311232 non-null  int64         \n",
      " 51  Qr__ml_h_                         311232 non-null  int64         \n",
      " 52  __PRE_POST                        311232 non-null  float64       \n",
      " 53  Qpfr__ml_h_                       311232 non-null  int64         \n",
      " 54  Set                               311232 non-null  object        \n",
      " 55  Run_Time__s_                      305868 non-null  float64       \n",
      " 56  Blood_Return                      311232 non-null  object        \n",
      " 57  Nb_Blood_Recirculation            311232 non-null  int64         \n",
      " 58  Blood_Recirculation_duration__mi  311232 non-null  float64       \n",
      " 59  Warning_during_treatment          311232 non-null  int64         \n",
      " 60  Nb_Bag_Changes                    311232 non-null  int64         \n",
      " 61  Total_mean_duration_per_Bag_Chan  311232 non-null  float64       \n",
      " 62  Acc_Ret_warning                   311232 non-null  int64         \n",
      " 63  End_Cause                         311232 non-null  object        \n",
      " 64  Dialysate_done__g_                311232 non-null  int64         \n",
      " 65  Dialysate_Expected__g_            311232 non-null  float64       \n",
      " 66  Delta_Dialysate__g_               311232 non-null  int64         \n",
      " 67  Pre_Replace_done__g_              311232 non-null  int64         \n",
      " 68  Post_Replace_done__g_             311232 non-null  int64         \n",
      " 69  Replace_done__g_                  311232 non-null  int64         \n",
      " 70  Replace_Expected__g_              311232 non-null  float64       \n",
      " 71  Delta_Replace__g_                 311232 non-null  int64         \n",
      " 72  PBP_done__g_                      311232 non-null  int64         \n",
      " 73  PBP_Expected__g_                  311232 non-null  float64       \n",
      " 74  Delta_PBP__g_                     311232 non-null  int64         \n",
      " 75  Effluent_done__g_                 311232 non-null  int64         \n",
      " 76  PFR_done__g_                      311232 non-null  int64         \n",
      " 77  PFR_Expected__g_                  311232 non-null  float64       \n",
      " 78  Delta_PFR__g_                     311232 non-null  int64         \n",
      " 79  Start_hour__hh_mm_                311232 non-null  object        \n",
      " 80  Start_line                        311232 non-null  int64         \n",
      " 81  Stop_line                         311232 non-null  int64         \n",
      " 82  Citrate_Solution                  311232 non-null  object        \n",
      " 83  Citrate_Concentration__mmol_L_    311232 non-null  object        \n",
      " 84  Citric_Acid_Concentration__mmol_  311232 non-null  object        \n",
      " 85  Citrate_Dose__mmol_L_             311232 non-null  object        \n",
      " 86  Calcium_Compensation____          311232 non-null  object        \n",
      " 87  Calcium_syringe_Concentration__m  311232 non-null  object        \n",
      " 88  Treatment_Duration__h_            311232 non-null  float64       \n",
      " 89  effluent2                         311232 non-null  int64         \n",
      " 90  delta_eff                         311232 non-null  int64         \n",
      " 91  max_line                          311232 non-null  int64         \n",
      " 92  reverse                           311232 non-null  int64         \n",
      " 93  sum                               311232 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(26), int64(55), object(12)\n",
      "memory usage: 223.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Info of the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88da049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_trt(df_spec_col):\n",
    "    '''The function returns a dictionary with keys associated to\n",
    "    the different treatment 'trt' values\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_spec_col : pandas.core.frame.DataFrame\n",
    "        DataFrame with specific columns related to the research focus \n",
    "\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df_dict : dict\n",
    "        Dictionary with DataFrames divided according to the treatment 'trt' value.\n",
    "        The output of dict.keys will be something as follows\n",
    "            dict_keys(['df_601', 'df_602', 'df_603', 'df_604', 'df_605', ...\n",
    "        df_601 is by itself a DataFrame with all the information corresponding to the\n",
    "        treatment 'trt' 601\n",
    "    '''\n",
    "    \n",
    "    #List with the different treatments values\n",
    "    trt = df_spec_col[\"trt\"].unique()\n",
    "    df_dict = {}\n",
    "\n",
    "    for value in trt:\n",
    "        # Create a dataframe for each unique value in trt and store it in the dictionary\n",
    "        df_dict[f\"df_{value}\"] = df_spec_col[df_spec_col['trt'] == value]\n",
    "        \n",
    "    return df_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd9da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_weight_vis(df_dict):\n",
    "    '''The function returns a sub DataFrame with the columns \n",
    "    trt and Patient_weight__Kg_\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dict : dict\n",
    "        Dictionary organized according to the different treatments 'trt'\n",
    "        values\n",
    "\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame with 'weight' set as index and 'trt' as reference value \n",
    "        the 'weight' (index) is sorted ascending\n",
    "        \n",
    "                    \n",
    "        weight(index)----trt\n",
    "        7.0--------------706\n",
    "        7.0--------------702\n",
    "        45.0-------------616\n",
    "        45.0-------------613\n",
    "        46.0-------------618\n",
    "\n",
    "    '''\n",
    "    merge_dict = {\n",
    "        'trt':[],\n",
    "        'weight':[]\n",
    "    }\n",
    "    for value in df_dict.keys():\n",
    "        df = df_dict[value]\n",
    "        trt = df[\"trt\"].unique()\n",
    "        weight = df[\"Patient_weight__Kg_\"].unique()\n",
    "        merge_dict['trt'].extend(trt)\n",
    "        merge_dict['weight'].extend(weight)\n",
    "        \n",
    "    df = pd.DataFrame(merge_dict)\n",
    "    df = df.sort_values(by=['weight', 'trt']).reset_index(drop=True)\n",
    "    df = df.set_index(\"weight\", inplace=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8623ed0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  <p>\n",
    "    <b>To Do</b>\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    I would like to have a function in which I choose, arbitrary, the maximum difference, between trt values, and according to this merge the DataFrames\n",
    "  </p>\n",
    "    \n",
    "  <p>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62c246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_to_merge(df, tolerance):\n",
    "    '''The function returns a DataFrame with boolean information, in the column merge, to \n",
    "    join DataFrames that correspond to the same patient\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame containing just the 'trt' and 'weight' value for all the cases of interest. Output of the \n",
    "        trt_weight_vis function\n",
    "        \n",
    "    tolerance : int\n",
    "        Tolerance of difference between the treatment values corresponding to a patient with the \n",
    "        same weight\n",
    "        i.e., a tolerance of 1 indicates that given the follwing DataFrame\n",
    "        \n",
    "            weight   trt    diff    tolerance   merge\n",
    "        [0] 7.0      702    4.0     False       False\n",
    "        [1] 7.0      706    93.0    False       False\n",
    "        [2] 45.0     613    3.0     False       False\n",
    "        [3] 45.0     616    2.0     False       False\n",
    "        [4] 46.0     618    1.0     True        True\n",
    "        [5] 46.0     619    7.0     False       False\n",
    "        \n",
    "        The row [4] will be True since, is the only one in which, the difference between trt[i] and \n",
    "        trt[i+1] is 1\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame with the following columns\n",
    "        ['weight'   'trt'    'diff'    'tolerance'   'merge']\n",
    "        \n",
    "        weight(index): weight value of the different patients\n",
    "        trt: treatment value\n",
    "        diff: difference between consecutive treatment values after sorting the DataFrame\n",
    "        tolerance:  if diff <= tolerance\n",
    "                        return True\n",
    "                    else\n",
    "                        return False\n",
    "        merge:  if (df['tolerance'] == True) & (shifted_index == df.index)\n",
    "                    return True\n",
    "                else\n",
    "                    return True\n",
    "        \n",
    "        shifted_index is the value of the index in the position [i+1] \n",
    "        \n",
    "        where: \n",
    "            i is the current index position \n",
    "                    \n",
    "    '''\n",
    "    # Shifting the 'trt' column by one position\n",
    "    df['shifted_trt'] = df['trt'].shift(-1)\n",
    "\n",
    "    # Calculating the difference between the 'trt' column and the shifted 'trt' column\n",
    "    df['diff'] = abs(df['trt'] - df['shifted_trt'])\n",
    "\n",
    "    # Dropping the 'shifted_trt' column as it's no longer needed\n",
    "    df.drop(columns=['shifted_trt'], inplace=True)\n",
    "    \n",
    "    #Search values in which the diff is <= tolerance\n",
    "    df['tolerance'] = df['diff'] <= tolerance\n",
    "    \n",
    "    #Create a new column merge to do the final comparison between trt values and weight values\n",
    "    shifted_index = df.index.to_series().shift(-1)\n",
    "    df['merge'] = ((df['tolerance'] == True) & (shifted_index == df.index))\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0152ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_recognition(df, columns, tolerance):\n",
    "    '''The function returns a DataFrame with columns containing information\n",
    "    useful to match patients with 'trt' number. This is a global function, cointaining all the \n",
    "    previous defined functions.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame with all the patients information\n",
    "    columns : list\n",
    "        Columns of interest i.e.,\n",
    "        columns=[\"Date__Heure\",\"P_Access\",\"P_Filter\",\"P_Effluent\",\"P_Return\", ...\n",
    "    tolerance : int\n",
    "        Tolerance of difference between the treatment values corresponding to a patient with the \n",
    "        same weight\n",
    "        i.e., a tolerance of 1 indicates that given the follwing DataFrame\n",
    "        \n",
    "            weight   trt    diff    tolerance   merge\n",
    "        [0] 7.0      702    4.0     False       False\n",
    "        [1] 7.0      706    93.0    False       False\n",
    "        [2] 45.0     613    3.0     False       False\n",
    "        [3] 45.0     616    2.0     False       False\n",
    "        [4] 46.0     618    1.0     True        True\n",
    "        [5] 46.0     619    7.0     False       False\n",
    "        \n",
    "        The value [4] will be True since, is the only one in which, the difference between trt[i] and \n",
    "        trt[i+1] is 1 \n",
    "\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame with the following columns\n",
    "        ['weight'   'trt'    'diff'    'tolerance'   'merge']\n",
    "        weight(index): weight value of the different patients\n",
    "        trt: treatment value\n",
    "        diff: difference between consecutive treatment values after sorting the DataFrame\n",
    "        tolerance:  if diff <= tolerance\n",
    "                        return True\n",
    "                    else\n",
    "                        return False\n",
    "        merge:  if (df['tolerance'] == True) & (shifted_index == df.index)\n",
    "                    return True\n",
    "                else\n",
    "                    return True\n",
    "        \n",
    "        shifted_index is the value of the index in the position [i+1] \n",
    "        \n",
    "        where: \n",
    "            i is the current index position \n",
    "        \n",
    "    '''\n",
    "    #Extract specific columns from the original DataFrame\n",
    "    df_spec_col = df[columns]\n",
    "    #Dictionary in which the indexes are the different trt values\n",
    "    df_dict = dict_trt(df_spec_col)\n",
    "    #DataFrame to evaluate weight with trt\n",
    "    df = trt_weight_vis(df_dict)\n",
    "    #DataFrame to evaluate which trt should be merged \n",
    "    df = trt_to_merge(df, tolerance)\n",
    "    \n",
    "    return df,df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86325d-e84e-4423-94c4-009a18e0932a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Part One</b> \n",
    "    <p>\n",
    "        <ul>\n",
    "        <li>DataFrame ['df_patients'] with information of the possible trt values to merge. This decision depends on the diff value; tolerance parameter.  </li>\n",
    "        <li>Dictionary ['df_dict_initial'] in which each key corresponds to the DataFrame of the respective trt number. The dictionary is a collection of DataFrames.</li>\n",
    "        </ul>\n",
    "             </p> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a870f96-a334-4a95-a19c-a5dca4dc62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns to consider from the original Data\n",
    "columns=[\"Date__Heure\",\"P_Access\",\"P_Filter\",\"P_Effluent\",\"P_Return\",\"Q_Blood_Pump\",\n",
    "          \"Q_Replacement\", \"Q_Dialysate\", \"Q_PBP\", \"Q_Patient_Fluid_Removal\", \"DeltaP\", \"TMP\", \"TMPa\", \"trt\", \n",
    "         \"Patient_weight__Kg_\", \"Set\"]\n",
    "df_patients, df_dict_initial = patient_recognition(df,columns,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792f9c8d-56bc-46e9-8835-103307d4889b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trt</th>\n",
       "      <th>diff</th>\n",
       "      <th>tolerance</th>\n",
       "      <th>merge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>702</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>706</td>\n",
       "      <td>93.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>613</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>616</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.0</th>\n",
       "      <td>618</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.0</th>\n",
       "      <td>619</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.0</th>\n",
       "      <td>626</td>\n",
       "      <td>23.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>603</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>612</td>\n",
       "      <td>56.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>668</td>\n",
       "      <td>117.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        trt   diff  tolerance  merge\n",
       "weight                              \n",
       "7.0     702    4.0      False  False\n",
       "7.0     706   93.0      False  False\n",
       "45.0    613    3.0      False  False\n",
       "45.0    616    2.0      False  False\n",
       "46.0    618    1.0       True   True\n",
       "46.0    619    7.0      False  False\n",
       "46.0    626   23.0      False  False\n",
       "50.0    603    9.0      False  False\n",
       "50.0    612   56.0      False  False\n",
       "50.0    668  117.0      False  False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patients.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0879b21c-e118-4093-8345-e2a01c6a6223",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Part Two</b> \n",
    "    <p>\n",
    "        Dictionary ['dictionary_merge']  with the information of the trt to be merged. Form the previous DataFrame ['df_patients'], if merge == True, we join the current [i] and the next trt [i+1] as treatments to be merged\n",
    "    </p> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45cb669e-27bd-449d-9a8b-2afa522c2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_merge(df_patients):\n",
    "    '''The function returns a dictionary with the pair of treatments to merge\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_patients : pandas.core.frame.DataFrame\n",
    "        DataFrame with the columns\n",
    "         weight   trt    diff    tolerance   merge\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trt_merge_dict : dict\n",
    "        Dictionary with tuples corresponding to the trt values to merge\n",
    "        \n",
    "    '''\n",
    "    df = df_patients.reset_index()\n",
    "    indexes = df[df['merge'] == True].index.tolist()\n",
    "    trt_merge_dict = {}\n",
    "    \n",
    "    for i in range(len(indexes)):  \n",
    "        index_val = indexes[i]\n",
    "        trt_val = df['trt'][index_val]\n",
    "        dict_name = f\"index_{index_val}\"\n",
    "        new_trt_merge = {'index': index_val, 'trt': {trt_val,trt_val+1}}\n",
    "        trt_merge_dict.update({dict_name: new_trt_merge})\n",
    "    \n",
    "    #Sort dict according to 'trt'\n",
    "    sorted_data = dict(sorted(trt_merge_dict.items(), key=lambda item: min(item[1]['trt'])))\n",
    "    \n",
    "    # Convert 'trt' sets to sorted lists\n",
    "    for key in sorted_data:\n",
    "        sorted_data[key]['trt'] = sorted(sorted_data[key]['trt'])\n",
    "        \n",
    "    return sorted_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "406798b8-18a7-4340-97b2-bcc4d6093d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_48': {'index': 48, 'trt': [608, 609]},\n",
       " 'index_4': {'index': 4, 'trt': [618, 619]},\n",
       " 'index_16': {'index': 16, 'trt': [624, 625]},\n",
       " 'index_66': {'index': 66, 'trt': [632, 633]},\n",
       " 'index_90': {'index': 90, 'trt': [649, 650]},\n",
       " 'index_116': {'index': 116, 'trt': [660, 661]},\n",
       " 'index_119': {'index': 119, 'trt': [680, 681]},\n",
       " 'index_154': {'index': 154, 'trt': [682, 683]},\n",
       " 'index_141': {'index': 141, 'trt': [684, 685]},\n",
       " 'index_142': {'index': 142, 'trt': [685, 686]},\n",
       " 'index_63': {'index': 63, 'trt': [687, 688]},\n",
       " 'index_145': {'index': 145, 'trt': [695, 696]},\n",
       " 'index_146': {'index': 146, 'trt': [696, 697]},\n",
       " 'index_24': {'index': 24, 'trt': [698, 699]},\n",
       " 'index_175': {'index': 175, 'trt': [712, 713]},\n",
       " 'index_72': {'index': 72, 'trt': [718, 719]},\n",
       " 'index_96': {'index': 96, 'trt': [720, 721]},\n",
       " 'index_98': {'index': 98, 'trt': [723, 724]},\n",
       " 'index_161': {'index': 161, 'trt': [737, 738]},\n",
       " 'index_162': {'index': 162, 'trt': [738, 739]},\n",
       " 'index_36': {'index': 36, 'trt': [744, 745]},\n",
       " 'index_37': {'index': 37, 'trt': [745, 746]},\n",
       " 'index_164': {'index': 164, 'trt': [749, 750]},\n",
       " 'index_166': {'index': 166, 'trt': [752, 753]},\n",
       " 'index_167': {'index': 167, 'trt': [753, 754]},\n",
       " 'index_40': {'index': 40, 'trt': [759, 760]},\n",
       " 'index_41': {'index': 41, 'trt': [760, 761]},\n",
       " 'index_56': {'index': 56, 'trt': [765, 766]},\n",
       " 'index_169': {'index': 169, 'trt': [767, 768]},\n",
       " 'index_170': {'index': 170, 'trt': [768, 769]},\n",
       " 'index_105': {'index': 105, 'trt': [770, 771]},\n",
       " 'index_107': {'index': 107, 'trt': [777, 778]},\n",
       " 'index_44': {'index': 44, 'trt': [779, 780]},\n",
       " 'index_10': {'index': 10, 'trt': [785, 786]},\n",
       " 'index_110': {'index': 110, 'trt': [787, 788]},\n",
       " 'index_112': {'index': 112, 'trt': [793, 794]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_merge_dict = dictionary_merge(df_patients)\n",
    "trt_merge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1dff5d1-aab8-4cbe-9d68-a4d18f6088bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>original_index</th>\n",
       "      <th>trt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index_48</td>\n",
       "      <td>48</td>\n",
       "      <td>[608, 609]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>index_4</td>\n",
       "      <td>4</td>\n",
       "      <td>[618, 619]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>index_16</td>\n",
       "      <td>16</td>\n",
       "      <td>[624, 625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>index_66</td>\n",
       "      <td>66</td>\n",
       "      <td>[632, 633]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>index_90</td>\n",
       "      <td>90</td>\n",
       "      <td>[649, 650]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>index_116</td>\n",
       "      <td>116</td>\n",
       "      <td>[660, 661]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>index_119</td>\n",
       "      <td>119</td>\n",
       "      <td>[680, 681]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>index_154</td>\n",
       "      <td>154</td>\n",
       "      <td>[682, 683]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>index_141</td>\n",
       "      <td>141</td>\n",
       "      <td>[684, 685]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>index_142</td>\n",
       "      <td>142</td>\n",
       "      <td>[685, 686]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>index_63</td>\n",
       "      <td>63</td>\n",
       "      <td>[687, 688]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>index_145</td>\n",
       "      <td>145</td>\n",
       "      <td>[695, 696]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>index_146</td>\n",
       "      <td>146</td>\n",
       "      <td>[696, 697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>index_24</td>\n",
       "      <td>24</td>\n",
       "      <td>[698, 699]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>index_175</td>\n",
       "      <td>175</td>\n",
       "      <td>[712, 713]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0  original_index         trt\n",
       "0    index_48              48  [608, 609]\n",
       "1     index_4               4  [618, 619]\n",
       "2    index_16              16  [624, 625]\n",
       "3    index_66              66  [632, 633]\n",
       "4    index_90              90  [649, 650]\n",
       "5   index_116             116  [660, 661]\n",
       "6   index_119             119  [680, 681]\n",
       "7   index_154             154  [682, 683]\n",
       "8   index_141             141  [684, 685]\n",
       "9   index_142             142  [685, 686]\n",
       "10   index_63              63  [687, 688]\n",
       "11  index_145             145  [695, 696]\n",
       "12  index_146             146  [696, 697]\n",
       "13   index_24              24  [698, 699]\n",
       "14  index_175             175  [712, 713]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dictionary to a DataFrame\n",
    "df_dict = pd.DataFrame.from_dict(trt_merge_dict, orient='index')\n",
    "\n",
    "# Reset the index to have a default integer index and move the original index to a column\n",
    "df_dict.reset_index(inplace=True)\n",
    "\n",
    "# Rename the column for clarity\n",
    "df_dict.rename(columns={'index': 'original_index'}, inplace=True)\n",
    "df_dict.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacb9451-6eaa-45d1-853d-3fc30ebd7b40",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    At this point we found the problem that in some cases we have to merge more than 2 treatments. Consider as example, the iloc indexes, [8] and [9]\n",
    "    <li>[8] corresponds to the treatments [684, 685] which are treatments corresponding to the same patient, beacause of the weight value</li>\n",
    "    <li>[9] corresponds to the treatments [685, 686] which are treatments corresponding to the same patient, beacause of the weight value</li>\n",
    "    We have an intersection at the value 685, this means that treatments 684, 685, 686 potentially corresponds to the same patient. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86071f1b-8c85-4b4c-a000-4f01b8f4857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_compar(df, i):\n",
    "    '''The function compares the trt values looking for an intersection between two continuous rows. i.e., [0] and [1] \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.core.frame.DataFrame\n",
    "        DataFrame with the columns\n",
    "\n",
    "        level_0\t    original_index\t    trt\n",
    "    [0]\tindex_48\t     48\t         [608, 609]\n",
    "    [1]\tindex_4\t          4\t         [618, 619]\n",
    "    [2]\tindex_16\t     16\t         [624, 625]\n",
    "\n",
    "    i : iterator to go through the different rows of the DataFrame      \n",
    "    Returns\n",
    "    -------\n",
    "    True / False : boolean\n",
    "        Boolean with the result of the comparisson\n",
    "        \n",
    "    '''\n",
    "    value_01 = list(df_dict['trt'].iloc[i])[1]\n",
    "    value_02 = list(df_dict['trt'].iloc[i+1])[0]\n",
    "    if value_01 == value_02:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9ddd142-0f74-4d6d-b8b2-bc49fa5cdb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_multiple_merge(df_dict):\n",
    "    '''The function returns a dictionary with the list of all the merges we could potentially do. \n",
    "    This information was obtained according to the trt value and the patient's weight.\n",
    "  \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dict : pandas.core.frame.DataFrame\n",
    "        DataFrame with the columns\n",
    "\n",
    "        level_0\t    original_index\t    trt\n",
    "    [0]\tindex_48\t     48\t         [608, 609]\n",
    "    [1]\tindex_4\t          4\t         [618, 619]\n",
    "    [2]\tindex_16\t     16\t         [624, 625]\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    dict : dict\n",
    "        Dictionary with the potential treatments to merge. We expect something like the following output\n",
    "        \n",
    "        {'index_48': {'values': [608, 609]},\n",
    "         'index_4': {'values': [618, 619]},\n",
    "         'index_16': {'values': [624, 625]},\n",
    "         'index_66': {'values': [632, 633]},\n",
    "         'index_90': {'values': [649, 650]},\n",
    "         'index_116': {'values': [660, 661]},\n",
    "         'index_119': {'values': [680, 681]},\n",
    "         'index_154': {'values': [682, 683]},\n",
    "         'index_142': {'values': ([684, 685], [685, 686])}, ...\n",
    "        \n",
    "    '''\n",
    "    dict={}\n",
    "    i=0\n",
    "    iter_range = len(df_dict)-1\n",
    "    #Given a DataFrame like the one from the example, we iterate through the whole list of trt values ['iter_range']\n",
    "    while i < iter_range:\n",
    "        result = trt_compar(df_dict,i)\n",
    "        list_trt = []\n",
    "        if result == True:\n",
    "            #Save the first tuple in a list\n",
    "            list_trt.append((df_dict['trt'].iloc[i],\n",
    "                       (df_dict['trt'].iloc[i+1])))\n",
    "            #Search more tuples to save in the list\n",
    "            for j in range(i+1,iter_range):\n",
    "                result = trt_compar(df_dict,j)\n",
    "                if result == True:\n",
    "                    list_trt.append([df_dict['trt'].iloc[j+1]])\n",
    "                else:\n",
    "                    diff = j-i\n",
    "                    i += diff\n",
    "                    break    \n",
    "    \n",
    "            list_name = f\"index_{df_dict['original_index'].iloc[i]}\"\n",
    "            list_merge = {'values': list_trt}\n",
    "            dict.update({list_name: list_merge})        \n",
    "        \n",
    "        else:\n",
    "            list_trt = list(df_dict['trt'].iloc[i])\n",
    "            list_name = f\"index_{df_dict['original_index'].iloc[i]}\"\n",
    "            list_merge = {'values': list_trt}\n",
    "            dict.update({list_name: list_merge})\n",
    "        i += 1\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9862c71a-4957-461d-b9e8-bcf644391a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = dictionary_multiple_merge(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cb46446-5e7c-40b6-a3f8-4e958f539796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_48': {'values': [608, 609]},\n",
       " 'index_4': {'values': [618, 619]},\n",
       " 'index_16': {'values': [624, 625]},\n",
       " 'index_66': {'values': [632, 633]},\n",
       " 'index_90': {'values': [649, 650]},\n",
       " 'index_116': {'values': [660, 661]},\n",
       " 'index_119': {'values': [680, 681]},\n",
       " 'index_154': {'values': [682, 683]},\n",
       " 'index_142': {'values': [([684, 685], [685, 686])]},\n",
       " 'index_63': {'values': [687, 688]},\n",
       " 'index_146': {'values': [([695, 696], [696, 697])]},\n",
       " 'index_24': {'values': [698, 699]},\n",
       " 'index_175': {'values': [712, 713]},\n",
       " 'index_72': {'values': [718, 719]},\n",
       " 'index_96': {'values': [720, 721]},\n",
       " 'index_98': {'values': [723, 724]},\n",
       " 'index_162': {'values': [([737, 738], [738, 739])]},\n",
       " 'index_37': {'values': [([744, 745], [745, 746])]},\n",
       " 'index_164': {'values': [749, 750]},\n",
       " 'index_167': {'values': [([752, 753], [753, 754])]},\n",
       " 'index_41': {'values': [([759, 760], [760, 761])]},\n",
       " 'index_56': {'values': [765, 766]},\n",
       " 'index_170': {'values': [([767, 768], [768, 769])]},\n",
       " 'index_105': {'values': [770, 771]},\n",
       " 'index_107': {'values': [777, 778]},\n",
       " 'index_44': {'values': [779, 780]},\n",
       " 'index_10': {'values': [785, 786]},\n",
       " 'index_110': {'values': [787, 788]}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c31a518-98ce-493d-8273-8d58d29162bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#Function to fix since is not producing the expected output\n",
    "def dictionary_multiple_merge_clean(dict, df_dict_initial):\n",
    "    '''The function returns a dictionary with the original DataFrames plus the DataFrames that potentially could be merged.\n",
    "    The dictionary is a collection of DataFrames\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dict : dict \n",
    "        dictionary with the values to merge. We expect something like the following input \n",
    "           {'index_48': {'values': [608, 609]},\n",
    "             'index_4': {'values': [618, 619]},\n",
    "             'index_16': {'values': [624, 625]},\n",
    "             'index_66': {'values': [632, 633]},\n",
    "             'index_90': {'values': [649, 650]},\n",
    "             'index_116': {'values': [660, 661]},\n",
    "             'index_119': {'values': [680, 681]},\n",
    "             'index_154': {'values': [682, 683]},\n",
    "             'index_142': {'values': ([684, 685], [685, 686])},   \n",
    "           \n",
    "    df_dict_initial : dict\n",
    "        initial dictionary in which each key corresponds to a different treatment 'trt' value\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_dict_initial_clean : dict\n",
    "        dictionary in which each key corresponds to a single or a merged DataFrame\n",
    "        \n",
    "    '''\n",
    "    for key, value in dict.items():\n",
    "        values = value['values']\n",
    "        # If values is a tuple, combine the inner lists into a single list\n",
    "        if isinstance(values, tuple):\n",
    "            combined_values = []\n",
    "            for sublist in values:\n",
    "                combined_values.extend(sublist)\n",
    "            values = combined_values\n",
    "        # Remove duplicates from the list\n",
    "        values = remove_duplicates(values)\n",
    "        # Add prefix \"df_\" to each element in the list\n",
    "        values = [f\"df_{v}\" for v in values]\n",
    "        #Merge the DataFrames\n",
    "        concat_df = pd.concat([df_dict_initial[key] for key in values], axis=0)\n",
    "        values_str = '-'.join(values)\n",
    "        name = f'{values_str}-concat'\n",
    "        df_dict_initial[name] = concat_df\n",
    "        return df_dict_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78eb7327-de88-4e36-b723-50e6177985e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('index_48', {'values': [608, 609]}), ('index_4', {'values': [618, 619]}), ('index_16', {'values': [624, 625]}), ('index_66', {'values': [632, 633]}), ('index_90', {'values': [649, 650]}), ('index_116', {'values': [660, 661]}), ('index_119', {'values': [680, 681]}), ('index_154', {'values': [682, 683]}), ('index_142', {'values': [([684, 685], [685, 686])]}), ('index_63', {'values': [687, 688]}), ('index_146', {'values': [([695, 696], [696, 697])]}), ('index_24', {'values': [698, 699]}), ('index_175', {'values': [712, 713]}), ('index_72', {'values': [718, 719]}), ('index_96', {'values': [720, 721]}), ('index_98', {'values': [723, 724]}), ('index_162', {'values': [([737, 738], [738, 739])]}), ('index_37', {'values': [([744, 745], [745, 746])]}), ('index_164', {'values': [749, 750]}), ('index_167', {'values': [([752, 753], [753, 754])]}), ('index_41', {'values': [([759, 760], [760, 761])]}), ('index_56', {'values': [765, 766]}), ('index_170', {'values': [([767, 768], [768, 769])]}), ('index_105', {'values': [770, 771]}), ('index_107', {'values': [777, 778]}), ('index_44', {'values': [779, 780]}), ('index_10', {'values': [785, 786]}), ('index_110', {'values': [787, 788]})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ba6124-1e26-4730-9478-6dc70b4730a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    \"\"\"Recursively flatten a nested list or tuple.\"\"\"\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            flat_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "def remove_duplicates(input_list):\n",
    "    \"\"\"Remove duplicates from a list while maintaining order.\"\"\"\n",
    "    unique_list = []\n",
    "    seen = set()\n",
    "    for item in input_list:\n",
    "        if item not in seen:\n",
    "            unique_list.append(item)\n",
    "            seen.add(item)\n",
    "    return unique_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f395c2-2717-4a21-ba0a-7581af56e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the final dictionary. Each key is a DataFrame; at the end we appended those corresponding to potentially merges\n",
    "\n",
    "for key, value in dict.items():\n",
    "    values = value['values']\n",
    "    # If values is a tuple, combine the inner lists into a single list\n",
    "    if isinstance(values, tuple):\n",
    "        combined_values = []\n",
    "        for sublist in values:\n",
    "            combined_values.extend(sublist)\n",
    "        values = combined_values\n",
    "    # Remove duplicates from the list\n",
    "    values = flatten_list(values)\n",
    "    values = remove_duplicates(values)\n",
    "    # Add prefix \"df_\" to each element in the list\n",
    "    values = [f\"df_{v}\" for v in values]\n",
    "    #Merge the DataFrames\n",
    "    concat_df = pd.concat([df_dict_initial[key] for key in values], axis=0)\n",
    "    values_str = '-'.join(values)\n",
    "    name = f'{values_str}-concat'\n",
    "    df_dict_initial[name] = concat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f69aa3e6-7613-45a1-95c6-fd8239346be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_601', 'df_602', 'df_603', 'df_604', 'df_605', 'df_606', 'df_607', 'df_608', 'df_609', 'df_610', 'df_611', 'df_612', 'df_613', 'df_614', 'df_615', 'df_616', 'df_617', 'df_618', 'df_619', 'df_620', 'df_621', 'df_622', 'df_623', 'df_624', 'df_625', 'df_626', 'df_627', 'df_628', 'df_629', 'df_630', 'df_631', 'df_632', 'df_633', 'df_634', 'df_635', 'df_636', 'df_637', 'df_639', 'df_641', 'df_642', 'df_643', 'df_644', 'df_645', 'df_646', 'df_647', 'df_648', 'df_649', 'df_650', 'df_651', 'df_652', 'df_653', 'df_654', 'df_655', 'df_656', 'df_657', 'df_658', 'df_659', 'df_660', 'df_661', 'df_662', 'df_663', 'df_664', 'df_665', 'df_666', 'df_667', 'df_668', 'df_669', 'df_670', 'df_672', 'df_673', 'df_674', 'df_675', 'df_676', 'df_677', 'df_678', 'df_679', 'df_680', 'df_681', 'df_682', 'df_683', 'df_684', 'df_685', 'df_686', 'df_687', 'df_688', 'df_689', 'df_690', 'df_691', 'df_692', 'df_693', 'df_694', 'df_695', 'df_696', 'df_697', 'df_698', 'df_699', 'df_700', 'df_701', 'df_702', 'df_703', 'df_704', 'df_705', 'df_706', 'df_707', 'df_708', 'df_709', 'df_710', 'df_711', 'df_712', 'df_713', 'df_714', 'df_715', 'df_716', 'df_717', 'df_718', 'df_719', 'df_720', 'df_721', 'df_723', 'df_724', 'df_725', 'df_726', 'df_727', 'df_728', 'df_729', 'df_730', 'df_731', 'df_732', 'df_733', 'df_734', 'df_735', 'df_736', 'df_737', 'df_738', 'df_739', 'df_740', 'df_741', 'df_742', 'df_743', 'df_744', 'df_745', 'df_746', 'df_747', 'df_748', 'df_749', 'df_750', 'df_751', 'df_752', 'df_753', 'df_754', 'df_755', 'df_756', 'df_757', 'df_758', 'df_759', 'df_760', 'df_761', 'df_762', 'df_763', 'df_764', 'df_765', 'df_766', 'df_767', 'df_768', 'df_769', 'df_770', 'df_771', 'df_772', 'df_773', 'df_774', 'df_775', 'df_776', 'df_777', 'df_778', 'df_779', 'df_780', 'df_781', 'df_782', 'df_783', 'df_784', 'df_785', 'df_786', 'df_787', 'df_788', 'df_789', 'df_790', 'df_791', 'df_792', 'df_793', 'df_794', 'df_795', 'df_796', 'df_608-df_609-concat', 'df_618-df_619-concat', 'df_624-df_625-concat', 'df_632-df_633-concat', 'df_649-df_650-concat', 'df_660-df_661-concat', 'df_680-df_681-concat', 'df_682-df_683-concat', 'df_684-df_685-df_686-concat', 'df_687-df_688-concat', 'df_695-df_696-df_697-concat', 'df_698-df_699-concat', 'df_712-df_713-concat', 'df_718-df_719-concat', 'df_720-df_721-concat', 'df_723-df_724-concat', 'df_737-df_738-df_739-concat', 'df_744-df_745-df_746-concat', 'df_749-df_750-concat', 'df_752-df_753-df_754-concat', 'df_759-df_760-df_761-concat', 'df_765-df_766-concat', 'df_767-df_768-df_769-concat', 'df_770-df_771-concat', 'df_777-df_778-concat', 'df_779-df_780-concat', 'df_785-df_786-concat', 'df_787-df_788-concat'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict_initial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74f4bb-ce7f-4963-85dc-427fa8f76c7c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  <p>\n",
    "    <b>Evaluation of the results</b>\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    \n",
    "\n",
    "  </p>\n",
    "    \n",
    "  <p>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4aa8cdfb-5d84-4b3f-99a6-2136604deba1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#Lets see how the time stamp of different trt that should be merged is set\n",
    "df_01 = df_dict_initial['df_759']\n",
    "df_02 = df_dict_initial['df_760']\n",
    "df_03 = df_dict_initial['df_761']\n",
    "df_01.head()\n",
    "df_02.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571a4b4-22d5-40ab-95f7-e2aee6b456f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  <p>\n",
    "    <b>Remark</b>\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    The trt values does not, necessarly, correspond to a new series of data. In some cases many of the values are repeated.\n",
    "    Lines of action:\n",
    "      <ul>\n",
    "            <li>Clean repeat information</li>\n",
    "      </ul>\n",
    "\n",
    "  </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcda7df-1c18-49da-8490-2967d6eb4c1c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    " <p>\n",
    "    The following function does a comparision only when we are considering 2 DataFrames. When we are considering more than 2 DataFrames, it just merge them. For the nature of the data is very unlikley that 3 potentially DataFrames, or more, to merge are not corresponding to the same patient. Anyway after the merge we can compare the difference between the first timestamp of information and the last one. \n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79c239fc-7702-4917-87c2-623d88f2bac2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "'''Function to see if the potentially DataFrames are close enough, according to the timestamp, so we can merge them. days indicates the maximum tolerance \n",
    "allowed between DataFrames'''\n",
    "#We can use the merge DataFrames directly, and compare the first and the last row of the timestamp. If the tolerance is satisfied we delete the original ones\n",
    "#otherwise, we keep them and delete the concat DataFrame\n",
    "\n",
    "days=5\n",
    "delete_elements=[]\n",
    "\n",
    "for name in df_dict_initial.keys():\n",
    "    if 'concat' in name:\n",
    "        # Remove '_concat' part\n",
    "        base_part = name.replace('-concat', '')\n",
    "        # Split the remaining part to get the variables\n",
    "        parts = base_part.split('-')\n",
    "        if len(parts) == 2:\n",
    "            name_01 = parts[0]\n",
    "            name_02 = parts[1]\n",
    "            #Load the DataFrames\n",
    "            df_01 = df_dict_initial[name_01]\n",
    "            df_02 = df_dict_initial[name_02]\n",
    "            # Print the variables\n",
    "            date_01 = df_01[\"Date__Heure\"].iloc[0]\n",
    "            date_02 = df_02[\"Date__Heure\"].iloc[0]\n",
    "            decision = abs(date_02 - date_01) <= pd.Timedelta(days=days)\n",
    "            #if decision is true we need to merge the DataFrames otherwise DataFrames keep the same\n",
    "            #the DataFrames are already merged we just need to cut from df_dict_initial the merged DataFrame or the\n",
    "            #individual ones\n",
    "            if decision == True:\n",
    "                #Delete the individual DataFrames from df_dict_initial\n",
    "                delete_elements.append(name_01)\n",
    "                delete_elements.append(name_02)\n",
    "            else:\n",
    "                #Delete the merged DataFrame\n",
    "                delete_elements.append(name)\n",
    "        else:\n",
    "            for item in parts:\n",
    "                delete_elements.append(item)\n",
    "        \n",
    "for item in delete_elements:\n",
    "    del df_dict_initial[item]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c75178f-c693-4821-97a3-7c131950d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function to see if the potentially DataFrames are close enough, according to the timestamp, so we can merge them. days indicates the maximum tolerance \n",
    "allowed between DataFrames'''\n",
    "days = 5\n",
    "delete_elements=[]\n",
    "\n",
    "for dframe in df_dict_initial.keys():\n",
    "    if 'concat' in dframe:\n",
    "        df_test = df_dict_initial[dframe]\n",
    "        initial = df_test[\"Date__Heure\"].iloc[0]\n",
    "        final = df_test[\"Date__Heure\"].iloc[-1]\n",
    "        decision = abs(initial - final) <= pd.Timedelta(days=days)\n",
    "        if decision == True:\n",
    "            #Delete individual DataFrames\n",
    "            base_part = dframe.replace('-concat', '')\n",
    "            parts = base_part.split('-')\n",
    "            for item in parts:\n",
    "                delete_elements.append(item) \n",
    "        else:\n",
    "            #Delete merge DataFrames\n",
    "            delete_elements.append(dframe)\n",
    "\n",
    "for element in delete_elements:\n",
    "    del df_dict_initial[element] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cbdc359-4ca0-4919-bad3-5aa3c10b2ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_601', 'df_602', 'df_603', 'df_604', 'df_605', 'df_606', 'df_607', 'df_608', 'df_609', 'df_610', 'df_611', 'df_612', 'df_613', 'df_614', 'df_615', 'df_616', 'df_617', 'df_620', 'df_621', 'df_622', 'df_623', 'df_626', 'df_627', 'df_628', 'df_629', 'df_630', 'df_631', 'df_632', 'df_633', 'df_634', 'df_635', 'df_636', 'df_637', 'df_639', 'df_641', 'df_642', 'df_643', 'df_644', 'df_645', 'df_646', 'df_647', 'df_648', 'df_649', 'df_650', 'df_651', 'df_652', 'df_653', 'df_654', 'df_655', 'df_656', 'df_657', 'df_658', 'df_659', 'df_662', 'df_663', 'df_664', 'df_665', 'df_666', 'df_667', 'df_668', 'df_669', 'df_670', 'df_672', 'df_673', 'df_674', 'df_675', 'df_676', 'df_677', 'df_678', 'df_679', 'df_689', 'df_690', 'df_691', 'df_692', 'df_693', 'df_694', 'df_695', 'df_696', 'df_697', 'df_700', 'df_701', 'df_702', 'df_703', 'df_704', 'df_705', 'df_706', 'df_707', 'df_708', 'df_709', 'df_710', 'df_711', 'df_714', 'df_715', 'df_716', 'df_717', 'df_725', 'df_726', 'df_727', 'df_728', 'df_729', 'df_730', 'df_731', 'df_732', 'df_733', 'df_734', 'df_735', 'df_736', 'df_740', 'df_741', 'df_742', 'df_743', 'df_747', 'df_748', 'df_751', 'df_755', 'df_756', 'df_757', 'df_758', 'df_762', 'df_763', 'df_764', 'df_765', 'df_766', 'df_770', 'df_771', 'df_772', 'df_773', 'df_774', 'df_775', 'df_776', 'df_777', 'df_778', 'df_781', 'df_782', 'df_783', 'df_784', 'df_787', 'df_788', 'df_789', 'df_790', 'df_791', 'df_792', 'df_793', 'df_794', 'df_795', 'df_796', 'df_618-df_619-concat', 'df_624-df_625-concat', 'df_660-df_661-concat', 'df_680-df_681-concat', 'df_682-df_683-concat', 'df_684-df_685-df_686-concat', 'df_687-df_688-concat', 'df_698-df_699-concat', 'df_712-df_713-concat', 'df_718-df_719-concat', 'df_720-df_721-concat', 'df_723-df_724-concat', 'df_737-df_738-df_739-concat', 'df_744-df_745-df_746-concat', 'df_749-df_750-concat', 'df_752-df_753-df_754-concat', 'df_759-df_760-df_761-concat', 'df_767-df_768-df_769-concat', 'df_779-df_780-concat', 'df_785-df_786-concat'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''At this point df_dict_initial contains DataFrames corresponding to a single treatment in \n",
    "case the previous merged conditions were not satisfied or a merged DataFrame in the opposite case.\n",
    "If the DataFrames were merged, the original ones were deleted'''\n",
    "df_dict_initial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac0fbf-7dde-4d00-8654-7d5f4c70794a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  <p>\n",
    "    <b>How to save this DataFrames?</b>\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    <li>Will depend on how we are going to use them for the model deployment</li> \n",
    "    \n",
    "\n",
    "  </p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd8de972-b7e5-41c1-9f0c-dd65160068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For quality control, we can verify the first and the last row of the concat DataFrames and see if the difference is not bigger than 3 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79eee480-0595-4bea-baf0-dfa7a31c7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_control(df_dict,days):\n",
    "    '''The function is a quality control check to see if the difference between the intial and the last timestamp is not considerably big.\n",
    "    We expect to have a difference of days because of the nature of the data.\n",
    "\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_dict : dict \n",
    "        dictionary in which each key is a DataFrame\n",
    "    days : int\n",
    "        tolerance in days\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None : list\n",
    "        the function prints 'Error + DataFrame name' i.e., 'Error df_601' if a DataFrame does not meet the given tolerance\n",
    "        \n",
    "    '''\n",
    "    for dframe in df_dict.keys():\n",
    "        df_test = df_dict[dframe]\n",
    "        initial = df_test[\"Date__Heure\"].iloc[0]\n",
    "        final = df_test[\"Date__Heure\"].iloc[-1]\n",
    "        decision = abs(initial - final) <= pd.Timedelta(days=days)\n",
    "        if decision == False:\n",
    "            print(f'Error {dframe}')\n",
    "        else:\n",
    "            continue\n",
    "    print('If no message was displayed before this, the quality control was passed')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5e54402-8415-4fd4-96fe-716ad18cea88",
   "metadata": {},
   "source": [
    "df_test = df_dict_initial['df_801']\n",
    "df_test.head(10)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a0f6cd3-5b77-4fd6-b2b8-4989f50a86ba",
   "metadata": {},
   "source": [
    "df_test.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddf28c15-11c1-431c-aa24-d0853769c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to save the final dictionary and see if we can open it in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "257c920f-3977-48d5-94b1-1593c8eb9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_no_ext = os.path.splitext(file)[0]\n",
    "name_save = f'{path_to_save}/{file_no_ext}.pkl' \n",
    "with open(name_save, 'wb') as file:\n",
    "    pickle.dump(df_dict_initial, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "853f224a-2237-43ed-b6e6-f5ca947ed318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/luisescobar/Documents/Thesis/DataSets/Dictionary/completo_800_output_file.pkl'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0f84e-230f-49e2-9ba8-c7c4659d59f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
