{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fefc642a-5b85-4c2c-8583-49fd04aee366",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "# Example data: Pandas DataFrames for multiple patients\n",
    "data = {\n",
    "    \"patient_1\": pd.DataFrame({\n",
    "        'x1': [1.0, 2.0, 3.0],\n",
    "        'x2': [2.0, 3.0, 4.0],\n",
    "        'x3': [1.0, 2.0, 1.5],\n",
    "        'x4': [0.5, 0.7, 0.9],\n",
    "        'y': [0, 1, 0]\n",
    "    }),\n",
    "    \"patient_2\": pd.DataFrame({\n",
    "        'x1': [2.0, 3.0],\n",
    "        'x2': [1.0, 2.0],\n",
    "        'x3': [0.5, 0.7],\n",
    "        'x4': [0.3, 0.6],\n",
    "        'y': [1, 0]\n",
    "    }),\n",
    "    \"patient_3\": pd.DataFrame({\n",
    "        'x1': [1.0, 1.0, 2.0, 2.0],\n",
    "        'x2': [2.0, 3.0, 1.5, 3.0],\n",
    "        'x3': [1.0, 0.8, 1.2, 1.1],\n",
    "        'x4': [0.5, 0.7, 0.6, 0.8],\n",
    "        'y': [0, 1, 0, 1]\n",
    "    }),\n",
    "    # Add more patients as needed\n",
    "}\n",
    "\n",
    "# Step 1: Prepare the data\n",
    "sequences = []\n",
    "labels = []\n",
    "lengths = []\n",
    "\n",
    "for patient_id, df in data.items():\n",
    "    # Extract explanatory variables (x1, x2, x3, x4)\n",
    "    sequence = torch.tensor(df[['x1', 'x2', 'x3', 'x4']].values, dtype=torch.float32)\n",
    "    \n",
    "    # Extract the target variable (y)\n",
    "    label = torch.tensor(df['y'].values[0], dtype=torch.float32)  # Assuming the same label for the entire series\n",
    "    \n",
    "    sequences.append(sequence)\n",
    "    labels.append(label)\n",
    "    lengths.append(len(sequence))\n",
    "\n",
    "# Convert labels to a tensor\n",
    "labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# Pad sequences to the maximum length\n",
    "padded_sequences = nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "# Convert lengths to a tensor\n",
    "lengths = torch.tensor(lengths)\n",
    "\n",
    "# Step 2: Define the GRU model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Pack the padded sequence\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.gru(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # We use the last hidden state of each sequence\n",
    "        idx = (lengths - 1).view(-1, 1).expand(len(lengths), output.size(2)).unsqueeze(1)\n",
    "        last_output = output.gather(1, idx).squeeze(1)\n",
    "\n",
    "        return torch.sigmoid(self.fc(last_output))\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = padded_sequences.size(2)  # Number of features (4 in this case: x1, x2, x3, x4)\n",
    "hidden_size = 64  # Number of GRU units\n",
    "model = GRUModel(input_size, hidden_size)\n",
    "\n",
    "# Step 3: Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 4: Training Loop\n",
    "#num_epochs = 100\n",
    "num_epochs =100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(padded_sequences, lengths)\n",
    "    loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Step 5: Test the model (optional)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(padded_sequences, lengths)\n",
    "    predictions = (test_outputs.squeeze() > 0.5).float()\n",
    "    print(f'Predictions: {predictions}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42804082-5eb7-40ca-a9a1-ac719dbcee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f462359f-be06-4324-bf1a-ddaf5c1a58b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrames from dictionary\n",
    "\n",
    "# Load the dictionary from the file\n",
    "path_to_read = '/Users/luisescobar/Documents/Thesis/DataSets/Dictionary'\n",
    "#path_to_save = '/Users/luisescobar/Documents/Thesis/DataSets/Dictionary'\n",
    "file_name = 'completo1007_(edit)_clotting.pkl'\n",
    "name_to_read = f'{path_to_read}/{file_name}'\n",
    "\n",
    "with open(name_to_read, 'rb') as file:\n",
    "    loaded_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db83075-fd8d-45d0-9388-4d957e305557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dictionary: 148\n",
      "Test Dictionary: 37\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "'''\n",
    "Maybe will be a better idea to split the final DataFrames into clotting and no clotting. Once we have this split we\n",
    "can divide in a better ratio for train and test  \n",
    "'''\n",
    "# Extract the keys\n",
    "keys = list(loaded_dict.keys())\n",
    "\n",
    "# Split the keys (80% train, 20% test)\n",
    "train_keys, test_keys = train_test_split(keys, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the train and test dictionaries\n",
    "train_dict = {key: loaded_dict[key] for key in train_keys}\n",
    "test_dict = {key: loaded_dict[key] for key in test_keys}\n",
    "\n",
    "print(\"Train Dictionary:\", len(train_dict))\n",
    "print(\"Test Dictionary:\", len(test_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d2c8a-8764-4073-a14b-90c1cab9f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "columns=[\"Date__Heure\",\"P_Access\",\"P_Filter\",\"P_Effluent\",\"P_Return\",\"Q_Blood_Pump\",\n",
    "          \"Q_Replacement\", \"Q_Dialysate\", \"Q_PBP\", \"Q_Patient_Fluid_Removal\", \"DeltaP\", \"TMP\", \"TMPa\", \"trt\", \n",
    "         \"Patient_weight__Kg_\", \"Set\"]\n",
    "\n",
    "For training we could remove\n",
    "0   Date__Heure ---> maybe we could find seasonality with this variable. However, we must transform the data  \n",
    "13  trt \n",
    "14  Patient_weight__Kg_ ---> we could include it for other models to see if it produce a prediction difference\n",
    "15  Set \n",
    "'''\n",
    "columns=[\"P_Access\",\"P_Filter\",\"P_Effluent\",\"P_Return\",\"Q_Blood_Pump\",\n",
    "         \"Q_Replacement\", \"Q_Dialysate\", \"Q_PBP\", \"Q_Patient_Fluid_Removal\", \n",
    "         \"DeltaP\", \"TMP\", \"TMPa\", \"Condition_1\", \"Condition_2\", \"Delta_P_ref\", \n",
    "         \"TMP_ref\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640111e-6242-43a3-b139-1d43060f99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare the data\n",
    "sequences = []\n",
    "labels = []\n",
    "lengths = []\n",
    "\n",
    "for patient_id, df in data.items():\n",
    "    # Extract explanatory variables (x1, x2, x3, x4)\n",
    "    sequence = torch.tensor(df[columns].values, dtype=torch.float32)\n",
    "    \n",
    "    # Extract the target variable (y)\n",
    "    label = torch.tensor(df['Clotting'].values[0], dtype=torch.float32)  # Assuming the same label for the entire series\n",
    "    \n",
    "    sequences.append(sequence)\n",
    "    labels.append(label)\n",
    "    lengths.append(len(sequence))\n",
    "\n",
    "# Convert labels to a tensor\n",
    "labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# Pad sequences to the maximum length\n",
    "padded_sequences = nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "# Convert lengths to a tensor\n",
    "lengths = torch.tensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f760cd-3edb-4eec-b059-9ab8fd9b5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the GRU model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Pack the padded sequence\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.gru(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # We use the last hidden state of each sequence\n",
    "        idx = (lengths - 1).view(-1, 1).expand(len(lengths), output.size(2)).unsqueeze(1)\n",
    "        last_output = output.gather(1, idx).squeeze(1)\n",
    "\n",
    "        return torch.sigmoid(self.fc(last_output))\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = padded_sequences.size(2)  # Number of features (4 in this case: x1, x2, x3, x4)\n",
    "hidden_size = 64  # Number of GRU units\n",
    "model = GRUModel(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f53a11-c055-48c1-996f-8637e562a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e3abd-ceda-42fa-8faf-2e957e22fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Training Loop\n",
    "#num_epochs = 100\n",
    "num_epochs =100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(padded_sequences, lengths)\n",
    "    loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e61cb7-6ea1-4664-97ea-e882339af8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Test the model (optional)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(padded_sequences, lengths)\n",
    "    predictions = (test_outputs.squeeze() > 0.5).float()\n",
    "    print(f'Predictions: {predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ded6da-c888-4279-a8d5-f01821cac2a3",
   "metadata": {},
   "source": [
    "Problems to address\n",
    "How dictionary will work during Step 1\n",
    "Should we normalize the values?\n",
    "Double check the step # Extract the target variable (y) since is assuming that the same label for the entire series\n",
    "What does this means?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
