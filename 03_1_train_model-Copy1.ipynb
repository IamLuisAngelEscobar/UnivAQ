{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a183fd63-1973-4c6c-a800-3d66878b175f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> Be careful before running this notebook since the new model will be overwritten on the previous one. Change the model's name before running</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696e1bdc-7fb7-4823-8300-6d286cd5262a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_Science_2024/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from auxiliary_functions import write_joblib, load_joblib\n",
    "from transformations import normaliztion, unbalanced\n",
    "from models import XGBmodel, RFmodel, LGBMmodel, Voting, Meta\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    " \n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b205be99-42c5-4cfc-9c9e-1c4dde6bb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 40\n",
    "path_to_read = '/Users/luisescobar/Documents/Thesis/DataSets/Dictionary/03_01_Train_Val_Test'\n",
    "path_to_save = f'/Users/luisescobar/Documents/Thesis/Models/TOP5_exp/xgb/lag_{lag}min'\n",
    "#path_to_save = '/Users/luisescobar/Documents/Thesis/Models'\n",
    "file_name_block = 'blocking_80.pkl'\n",
    "file_name_no_block = 'no_blocking_80.pkl'\n",
    "\n",
    "dict_block = load_joblib(path_to_read, file_name_block)\n",
    "dict_no_block = load_joblib(path_to_read, file_name_no_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901c9530-a30b-4fd5-ab4c-d726074524a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "loaded_dict = {**dict_block, **dict_no_block}\n",
    "\n",
    "items = list(loaded_dict.items())\n",
    "random.shuffle(items)\n",
    "loaded_dict = dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0167c0a0-d072-4b96-8db9-5f8117b334f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "564\n",
      "636\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_block))\n",
    "print(len(dict_no_block))\n",
    "print(len(loaded_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38321f1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> Line 8 and 9 must be commented in case we want to include 'DeltaP', 'TMP', 'TMPa'</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af0ea6a-0332-4a0a-bfb3-0dbddc32dea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1276750 entries, 0 to 1276749\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count    Dtype  \n",
      "---  ------      --------------    -----  \n",
      " 0   P_Access    1276750 non-null  int64  \n",
      " 1   P_Filter    1276750 non-null  int64  \n",
      " 2   P_Return    1276750 non-null  int64  \n",
      " 3   DeltaP      1276750 non-null  int64  \n",
      " 4   TMP         1276750 non-null  float64\n",
      " 5   Clotting_2  1276750 non-null  int64  \n",
      "dtypes: float64(1), int64(5)\n",
      "memory usage: 58.4 MB\n"
     ]
    }
   ],
   "source": [
    "#Create a single DataFrame ready to train\n",
    "dataframes_list = list(loaded_dict.values())\n",
    "\n",
    "# Concatenate all DataFrames vertically. Each Data Frame starts with zero so a \n",
    "combined_df = pd.concat(dataframes_list, ignore_index=False)\n",
    "\n",
    "# Drop highly correlated columns\n",
    "#d_columns = ['Q_Blood_Pump','Q_Replacement','Q_Dialysate','Q_PBP','Q_Patient_Fluid_Removal', 'DeltaP', 'TMPa']\n",
    "d_columns = ['P_Effluent','Q_Blood_Pump','Q_Replacement','Q_Dialysate','Q_PBP', 'Q_Patient_Fluid_Removal', 'TMPa']\n",
    "combined_df.drop(d_columns, axis=1, inplace=True)\n",
    "\n",
    "#combined_df = pd.concat(dataframes_list, ignore_index=True)\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e5e538-0fcf-4d3c-8ba1-3fc28908d90b",
   "metadata": {},
   "source": [
    "Construct the model we will try with Random Forest and XGBoost\n",
    "For this we could use an autocorrelation matrix to see until which point lag value has prediction power\n",
    "Autocorrelation is not a good approach since we are not using time dependent data\n",
    "Run the experiment for three lag values and see what happen\n",
    "10 min\n",
    "30 min\n",
    "40 min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65bafda-eb24-453f-86ec-465bea620cb7",
   "metadata": {},
   "source": [
    "The use of \n",
    "df_lagged = combined_df.dropna()\n",
    "Does not erase information from the original Data Frame?\n",
    "it does but on the new DataFrame df_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0d3f42-8861-412e-ae2b-e82dd6e08bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of blocking points 4867\n",
      "Baseline model accuracy 0.9961879772860779\n"
     ]
    }
   ],
   "source": [
    "#Baseline model\n",
    "#The baseline model classifies all the points as zero, since most of them are zero. Therefore, it never recognizes blocking events\n",
    "count_of_ones = combined_df['Clotting_2'].sum()\n",
    "accuracy_baseline = (len(combined_df)-count_of_ones)/len(combined_df)\n",
    "print(f'Total number of blocking points {count_of_ones}')\n",
    "print(f'Baseline model accuracy {accuracy_baseline}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3ba83-ab22-48a7-ad05-667e876e6553",
   "metadata": {},
   "source": [
    "Parameters that changed during the model deployment:\n",
    "* test\n",
    "* balance\n",
    "* unbalanced_percentage\n",
    "* test_size on:\n",
    "* X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)\n",
    "* values I used 0.2, 0.1, 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00d445cc-5d44-4441-a7e9-0a613c16ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for lag 40\n",
      "**** This in NOT a test ****\n",
      "Balance percentage 0.1\n",
      "Original class distribution: Counter({0: 1144655, 1: 4384})\n",
      "Resampled class distribution: Counter({0: 1144655, 1: 114278})\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters found: {'alpha': 0.6454722959071678, 'colsample_bytree': 0.6708442717628196, 'lambda': 0.9404585843529143, 'learning_rate': 0.2961785731007762, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 479, 'scale_pos_weight': 37, 'subsample': 0.9713274250350902}\n",
      "ROC-AUC Score: 0.9680844632203867\n",
      "Confusion Matrix:\n",
      "[[126706    482]\n",
      " [    29    454]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    127188\n",
      "           1       0.49      0.94      0.64       483\n",
      "\n",
      "    accuracy                           1.00    127671\n",
      "   macro avg       0.74      0.97      0.82    127671\n",
      "weighted avg       1.00      1.00      1.00    127671\n",
      "\n",
      "Total number of blocking points 483\n",
      "Length of the test vector 127671\n",
      "Accuracy baseline model 0.996216838592946\n"
     ]
    }
   ],
   "source": [
    "my_dict = {}\n",
    "test = False\n",
    "balance = True\n",
    "model = 'XGB'  # Must be 'RF', 'XGB' or 'LGBM' or 'VOTE' or 'META'\n",
    "file_name = 'xgb_model.pkl'\n",
    "unbalanced_method = 'adasyn'\n",
    "unbalanced_percentage = 0.1\n",
    "test_size = 0.1\n",
    "\n",
    "# Lag values\n",
    "#lags = [10, 30, 40]\n",
    "lags = [lag]\n",
    "\n",
    "\n",
    "# Step 3: Iterate through each lag and create lagged features\n",
    "for lag in lags:\n",
    "    print(f\"\\nTraining model for lag {lag}\")\n",
    "\n",
    "    # Create lagged features for each column except the target column\n",
    "    for column in combined_df.columns:\n",
    "        if column != 'Clotting_2':  # Skip the target column\n",
    "            combined_df[f'{column}_lag_{lag}'] = combined_df[column].shift(lag)\n",
    "    \n",
    "    # Remove rows with NaN values (due to shifting)\n",
    "    df_lagged = combined_df.dropna()\n",
    "\n",
    "    # Prepare features (X) and target (y)\n",
    "    # Drop original columns and only use lagged features\n",
    "    lagged_columns = [col for col in df_lagged.columns if 'lag_' in col]\n",
    "    X = df_lagged[lagged_columns]\n",
    "    y = df_lagged['Clotting_2']  # Target variable\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True)\n",
    "\n",
    "    if test is True:\n",
    "        # Use a smaller sample for testing purposes\n",
    "        X_train = X_train.sample(frac=0.01, random_state=42)  # Use only frac% of the data\n",
    "        y_train = y_train.loc[X_train.index]\n",
    "        X_test = X_test.sample(frac=0.01, random_state=42)\n",
    "        y_test = y_test.loc[X_test.index]\n",
    "        print('**** Running test ****')\n",
    "    else:\n",
    "        print('**** This in NOT a test ****')\n",
    "    \n",
    "    # The scaler is saved in path_to_save\n",
    "    X_train_scaled, X_test_scaled = normaliztion(X_train, X_test, path_to_save)\n",
    "\n",
    "    if balance is True:\n",
    "        print(f'Balance percentage {unbalanced_percentage}')\n",
    "        method = unbalanced(unbalanced_method, unbalanced_percentage)\n",
    "        X_train_resampled, y_train_resampled = method.fit_resample(X_train_scaled, y_train)\n",
    "        # Check class distribution after resampling\n",
    "        print(f\"Original class distribution: {Counter(y_train)}\")\n",
    "        print(f\"Resampled class distribution: {Counter(y_train_resampled)}\")\n",
    "    else:\n",
    "        #X_train_resampled =  X_train_scaled\n",
    "        #y_train_resampled = y_train\n",
    "        X_train_resampled, y_train_resampled = X_train_scaled, y_train\n",
    "        print(f\"Original class distribution: {Counter(y_train)}\")\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    if model == 'XGB':\n",
    "        #Save the model\n",
    "        model = XGBmodel(X_train_resampled, y_train_resampled)\n",
    "        write_joblib(model, path_to_save, file_name)\n",
    "        \n",
    "    elif model == 'RF':               \n",
    "        #Save the model\n",
    "        model = RFmodel(X_train_resampled, y_train_resampled)\n",
    "        write_joblib(model, path_to_save, file_name)\n",
    "        \n",
    "    elif model =='LGBM':\n",
    "        #Save the model\n",
    "        model = LGBMmodel(X_train_resampled, y_train_resampled)              \n",
    "        write_joblib(model, path_to_save, file_name)\n",
    "\n",
    "    elif model == 'VOTE':\n",
    "        model = Voting(X_train_resampled, y_train_resampled)\n",
    "        write_joblib(model, path_to_save, file_name)\n",
    "    elif model =='META':\n",
    "        model = Meta(X_train_resampled, y_train_resampled)\n",
    "        write_joblib(model, path_to_save, file_name)\n",
    "\n",
    "        \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    my_dict[f'y_pred_{lag}'] = y_pred\n",
    "    my_dict[f'y_test_{lag}'] = y_test.tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ROC-AUC Score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"Classification Report:\\n{class_report}\")\n",
    "    print(f'Total number of blocking points {y_test.sum()}')\n",
    "    print(f'Length of the test vector {len(y_test)}')\n",
    "    print(f'Accuracy baseline model {(len(y_test)-y_test.sum())/len(y_test)}')\n",
    "\n",
    "    # Optionally, clean up the DataFrame to prepare for the next lag\n",
    "    # (by dropping the lagged columns for the current lag)\n",
    "    combined_df = combined_df.drop(columns=[f'{column}' for column in combined_df.columns if f'lag_{lag}' in column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23934962-758a-41c8-beb9-9187a16bed3e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Evaluate how data looks after the training/test splitting </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
