{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4047e964-81f3-4d5e-a78b-95b28a005568",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> \n",
    "\n",
    "<div>\n",
    "    This is a duplicate of notebook <b>04_prediction-best-practices </b>, considering the new performance metric adjustments the methodolgy to evaluate the test data changes to a sequential approach. Each time series is evaluated independently instead of the concatenations done before.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f0b718-f2e0-4517-a089-1e39755a5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import random \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from auxiliary_functions import load_joblib\n",
    "from evaluation_metrics import similarity, similarity_block, distance_pred, performance, time_window_perform, oscillation_red, class_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c6efa-52cb-49f6-8396-60c14a004471",
   "metadata": {},
   "source": [
    "# For testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f4b9f6-c574-4179-a8ae-f5e791299c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model and data\n",
    "path_to_read1 = '/Users/luisescobar/Documents/Thesis/Models/ADASYN/point_six_train_2'\n",
    "path_to_read2 = '/Users/luisescobar/Documents/Thesis/DataSets/Dictionary/03_01_Train_Val_Test'\n",
    "path_to_read3 = '/Users/luisescobar/Documents/Thesis/Models'\n",
    "filename_model = 'xgboost_model.pkl'\n",
    "filename_clot = 'blocking_20.pkl'\n",
    "filename_noclot = 'no_blocking_20.pkl'\n",
    "filename_scaler = 'scaler.pkl'\n",
    "\n",
    "#model_loaded = load_joblib(path_to_read1, filename_model)\n",
    "model_loaded = load_joblib(path_to_read1, filename_model)\n",
    "scaler_loaded = load_joblib(path_to_read3, filename_scaler)\n",
    "clot_dict = load_joblib(path_to_read2, filename_clot)\n",
    "no_clot_dict = load_joblib(path_to_read2, filename_noclot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88b7acd-bfe4-4b28-9422-7583e6442956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_1', 'df_923', 'df_680-df_681-concat', 'df_654', 'df_311', 'df_344-df_345-df_346-concat', 'df_902', 'df_486', 'df_513', 'df_62', 'df_653', 'df_783', 'df_790', 'df_247', 'df_190', 'df_751', 'df_764', 'df_859', 'df_115'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choose arbitrary a dataset from the blocking class\n",
    "clot_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41335bf8-2a00-4679-b8fd-2e898c00399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 10\n",
    "use_threshold = False\n",
    "\n",
    "data_p0 = []\n",
    "data_r0 = []\n",
    "data_p1 = []\n",
    "data_r1 = []\n",
    "\n",
    "for df_name in clot_dict.keys():\n",
    "    #print(df_name)\n",
    "    df = clot_dict[df_name]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create lagged features for each column except the target column\n",
    "    for column in df.columns:\n",
    "        if column != 'Clotting_2':  # Skip the target column\n",
    "            df[f'{column}_lag_{lag}'] = df[column].shift(lag)\n",
    "    \n",
    "    # Remove rows with NaN values (due to shifting)\n",
    "    df_lagged = df.dropna()\n",
    "    df_lagged = df_lagged.reset_index(drop=True)\n",
    "    \n",
    "    # Prepare features (X) and target (y)\n",
    "    # Drop original columns and only use lagged features\n",
    "    lagged_columns = [col for col in df_lagged.columns if 'lag_' in col]\n",
    "    X = df_lagged[lagged_columns]\n",
    "    X = scaler_loaded.transform(X)\n",
    "    y_true = df_lagged['Clotting_2'] \n",
    "    \n",
    "    \n",
    "    \n",
    "    if use_threshold == False:\n",
    "        # Make predictions using the lag feature matrix\n",
    "        y_pred = model_loaded.predict(X)\n",
    "        \n",
    "    else:\n",
    "        # Get predicted probabilities\n",
    "        probs = model_loaded.predict_proba(X)\n",
    "        \n",
    "        # Define a custom threshold, e.g., 0.7\n",
    "        threshold = 0.7\n",
    "        \n",
    "        # Assign Class 1 if the probability for Class 1 is greater than or equal to the threshold, else Class 0\n",
    "        y_pred = (probs[:, 1] >= threshold).astype(int)\n",
    "    \n",
    "    # Regularization on oscillations (on test)\n",
    "    y_pred_reg = oscillation_red(y_pred, 0.4, 20)\n",
    "    \n",
    "    \n",
    "    p0, r0, p1, r1 =  time_window_perform(y_pred_reg, y_true, 20, False)\n",
    "    \n",
    "    data_p0.append(p0)\n",
    "    data_r0.append(r0)\n",
    "    data_p1.append(p1)\n",
    "    data_r1.append(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb90424-669a-41e9-a944-59425137e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "+-----+-------------+----------+\n",
      "|     |   precision |   recall |\n",
      "+=====+=============+==========+\n",
      "|   0 |    0.939662 | 0.969367 |\n",
      "+-----+-------------+----------+\n",
      "|   1 |    0.528599 | 0.520372 |\n",
      "+-----+-------------+----------+\n"
     ]
    }
   ],
   "source": [
    "class_report(data_p0, data_r0, data_p1, data_r1, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f204976-1e22-4d83-a30f-c5ebcd7e4d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "+-----+-------------+----------+\n",
      "|     |   precision |   recall |\n",
      "+=====+=============+==========+\n",
      "|   0 |    0.989749 |  1       |\n",
      "+-----+-------------+----------+\n",
      "|   1 |    0.717647 |  0.71875 |\n",
      "+-----+-------------+----------+\n"
     ]
    }
   ],
   "source": [
    "class_report(data_p0, data_r0, data_p1, data_r1, 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f7e1925-86d7-4423-88c1-a5eb3ee48761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.875,\n",
       " 0.75,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.75,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8181818181818182,\n",
       " 0.11538461538461539,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.4230769230769231,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec0e96-9563-4aad-be50-386fe25c2458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
