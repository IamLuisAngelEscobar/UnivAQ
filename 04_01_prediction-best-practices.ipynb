{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4047e964-81f3-4d5e-a78b-95b28a005568",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> \n",
    "\n",
    "<div>\n",
    "    This is a duplicate of notebook <b>04_prediction-best-practices </b>, considering the new performance metric adjustments the methodolgy to evaluate the test data changes to a sequential approach. Each time series is evaluated independently instead of the concatenations done before.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0b718-f2e0-4517-a089-1e39755a5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auxiliary_functions import load_joblib\n",
    "from evaluation_metrics import  time_window_perform, oscillation_red, class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c6efa-52cb-49f6-8396-60c14a004471",
   "metadata": {},
   "source": [
    "# For testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e367f-d8ec-4d97-abc3-1ac10b6f4c0f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>NOTE</b> \n",
    "\n",
    "<div>\n",
    "    Choose the working_class correctly. 1 for blocking, 0 for non-blocking.\n",
    "    Additionally pay attention to the lag value.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f4b9f6-c574-4179-a8ae-f5e791299c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model and data\n",
    "lag = 60\n",
    "path_to_read1 = f'/Users/luisescobar/Documents/Thesis/Models/original/lag_{lag}min'\n",
    "path_to_read2 = '/Users/luisescobar/Documents/Thesis/DataSets/Dictionary/03_01_Train_Val_Test'\n",
    "#path_to_read3 = '/Users/luisescobar/Documents/Thesis/Models'\n",
    "filename_model = 'xgboost_model.pkl'\n",
    "filename_clot = 'blocking_20.pkl'\n",
    "filename_noclot = 'no_blocking_20.pkl'\n",
    "filename_scaler = 'scaler.pkl'\n",
    "\n",
    "#model_loaded = load_joblib(path_to_read1, filename_model)\n",
    "model_loaded = load_joblib(path_to_read1, filename_model)\n",
    "scaler_loaded = load_joblib(path_to_read1, filename_scaler)\n",
    "clot_dict = load_joblib(path_to_read2, filename_clot)\n",
    "no_clot_dict = load_joblib(path_to_read2, filename_noclot)\n",
    "\n",
    "working_class = 1 #must be 1 (clot)/ 0 (non-clot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88b7acd-bfe4-4b28-9422-7583e6442956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['df_1', 'df_923', 'df_680-df_681-concat', 'df_654', 'df_311', 'df_344-df_345-df_346-concat', 'df_902', 'df_486', 'df_513', 'df_62', 'df_653', 'df_783', 'df_790', 'df_247', 'df_190', 'df_751', 'df_764', 'df_859', 'df_115'])\n"
     ]
    }
   ],
   "source": [
    "#Choose arbitrary a dataset from the blocking class\n",
    "if working_class == 1:\n",
    "    print(clot_dict.keys())\n",
    "    dict_eval = clot_dict\n",
    "elif working_class == 0:\n",
    "    print(no_clot_dict.keys())\n",
    "    dict_eval = no_clot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41335bf8-2a00-4679-b8fd-2e898c00399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_threshold = False\n",
    "\n",
    "data_p0 = []\n",
    "data_r0 = []\n",
    "data_p1 = []\n",
    "data_r1 = []\n",
    "\n",
    "for df_name in dict_eval.keys():\n",
    "    #print(df_name)\n",
    "    df = dict_eval[df_name]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create lagged features for each column except the target column\n",
    "    for column in df.columns:\n",
    "        if column != 'Clotting_2':  # Skip the target column\n",
    "            df[f'{column}_lag_{lag}'] = df[column].shift(lag)\n",
    "    \n",
    "    # Remove rows with NaN values (due to shifting)\n",
    "    df_lagged = df.dropna()\n",
    "    df_lagged = df_lagged.reset_index(drop=True)\n",
    "    \n",
    "    # Prepare features (X) and target (y)\n",
    "    # Drop original columns and only use lagged features\n",
    "    lagged_columns = [col for col in df_lagged.columns if 'lag_' in col]\n",
    "    X = df_lagged[lagged_columns]\n",
    "    X = scaler_loaded.transform(X)\n",
    "    y_true = df_lagged['Clotting_2'] \n",
    "    \n",
    "    \n",
    "    \n",
    "    if use_threshold is False:\n",
    "        # Make predictions using the lag feature matrix\n",
    "        y_pred = model_loaded.predict(X)\n",
    "        \n",
    "    else:\n",
    "        # Get predicted probabilities\n",
    "        probs = model_loaded.predict_proba(X)\n",
    "        \n",
    "        # Define a custom threshold, e.g., 0.7\n",
    "        threshold = 0.7\n",
    "        \n",
    "        # Assign Class 1 if the probability for Class 1 is greater than or equal to the threshold, else Class 0\n",
    "        y_pred = (probs[:, 1] >= threshold).astype(int)\n",
    "    \n",
    "    # Regularization on oscillations (on test)\n",
    "    y_pred_reg = oscillation_red(y_pred, 0.4, 20)\n",
    "    \n",
    "    \n",
    "    p0, r0, p1, r1 =  time_window_perform(y_pred_reg, y_true, 20, False)\n",
    "    \n",
    "    data_p0.append(p0)\n",
    "    data_r0.append(r0)\n",
    "    data_p1.append(p1)\n",
    "    data_r1.append(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb90424-669a-41e9-a944-59425137e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "+-----+-------------+----------+\n",
      "|     |   precision |   recall |\n",
      "+=====+=============+==========+\n",
      "|   0 |    0.921763 | 0.970503 |\n",
      "+-----+-------------+----------+\n",
      "|   1 |    0.285525 | 0.328878 |\n",
      "+-----+-------------+----------+\n"
     ]
    }
   ],
   "source": [
    "class_report(data_p0, data_r0, data_p1, data_r1, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f204976-1e22-4d83-a30f-c5ebcd7e4d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "+-----+-------------+----------+\n",
      "|     |   precision |   recall |\n",
      "+=====+=============+==========+\n",
      "|   0 |    0.970588 |        1 |\n",
      "+-----+-------------+----------+\n",
      "|   1 |    0        |        0 |\n",
      "+-----+-------------+----------+\n"
     ]
    }
   ],
   "source": [
    "class_report(data_p0, data_r0, data_p1, data_r1, 'median')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
